{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import string\n",
    "import random\n",
    "import random\n",
    "import bitarray\n",
    "import mmh3\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic data structures let us save RAM by sacrificing accuracy. Different types of probabilistic data structures do this differently, and therefore they are more useful for different applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morris counter\n",
    "\n",
    "A Morris counter is useful when we need to count large numbers but precission is not that important. This is how it works:\n",
    "\n",
    "- set the counter at i = 0\n",
    "- when querying the counter, return 2 ^ i, and increment i with probability 1 / 2 ^ i\n",
    "\n",
    "So, for instance, the first time we query the counter we obtain the value 1. Next time we will get the value 2. Then we will get the value 2 or 4 with 0.5 probability each, etc. The more we count, the more inaccurate the value is. Therefore, this method is useful when we are interested to know orders of magniture.\n",
    "\n",
    "If we only use one byte to store the value of i (so that the maximum value of i is 256), we can count up to 2 ^ 256, which would require many more bytes.\n",
    "\n",
    "In the plot below, the continuous line represents the increment of a normal integer, which requires multiple bytes. The dotted lines represent the increment of three different 1 byte Morris counter. We compare to three runs of the Morris counter due to the random nature of the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morris_counter(n):\n",
    "    it = 0\n",
    "    i = 0\n",
    "    while it < n:\n",
    "        yield 2 ** i\n",
    "        \n",
    "        if random.random() <= 1 / (2 ** i):\n",
    "            i = i + 1\n",
    "            \n",
    "        it = it + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(10000), range(10000), lw = 2)\n",
    "ax.plot(range(10000), list(morris_counter(10000)), '--')\n",
    "ax.plot(range(10000), list(morris_counter(10000)), '--')\n",
    "ax.plot(range(10000), list(morris_counter(10000)), '--')\n",
    "fig.set_figwidth(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bloom filters\n",
    "\n",
    "Bloom filters are data structures that were created to answer the quesition of whether we have seen an item before. An item is represented by a set of hash codes. The status of hash codes is stored as a list of booleans. Initially, all values are false. When we insert an item, the index of all its derived hash codes is set to True. To test whether an object was already inserted, we just check the value of its corresponding hash indexes. \n",
    "\n",
    "There are no false negatives (if the Bloom filter says that we didn't see an item, we certainly didn't) and there is a 0.5% probability of false positives (if we identify an item as already in the data structure, there is a 0.5% probability that this is due to hash collisions.)\n",
    "\n",
    "The length of the bool array (the number of bits) and the number of hash values to represent each item depends on the required capacity and error rate. \n",
    "\n",
    "In this example we are using bits to represent the bool array instead of booleans, because booleans actually take 4 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BloomFilter(object):\n",
    "    def __init__(self, capacity, error = 0.005):\n",
    "        '''\n",
    "        Initialise a Bloom filter with given capacity and a false positive rate\n",
    "        '''\n",
    "        self.capacity = capacity\n",
    "        self.error = error\n",
    "        self.num_bits = int(-capacity * math.log(error) / math.log(2)**2) + 1\n",
    "        self.num_hashes = int(self.num_bits * math.log(2) / float(capacity)) + 1\n",
    "        self.data = bitarray.bitarray(self.num_bits)\n",
    "        \n",
    "    def _indexes(self, key):\n",
    "        h1, h2 = mmh3.hash64(key)\n",
    "        for i in range(self.num_hashes):\n",
    "            yield (h1 + i * h2) % self.num_bits\n",
    "            \n",
    "    def add(self, key):\n",
    "        for index in self._indexes(key):\n",
    "            self.data[index] = True\n",
    "            \n",
    "    def __contains__(self, key):\n",
    "        return all(self.data[index] for index in self._indexes(key))\n",
    "    \n",
    "    def __len__(self):\n",
    "        num_bits_on = self.data.count(True)\n",
    "        return -1.0 * self.num_bits * \\\n",
    "                      math.log(1.0 - num_bits_on / float(self.num_bits)) / \\\n",
    "                      float(self.num_hashes)\n",
    "            \n",
    "    @staticmethod\n",
    "    def untion(bloom_a, bloom_b):\n",
    "        assert bloom_a.capacity == bloom_b.capacity\n",
    "        assert bloom_a.error == bloom_b.error\n",
    "        \n",
    "        bloom_union = BloomFilter(bloom_a.capacity, bloom_a.error)\n",
    "        bloom_union.data = bloom_a.data | bloom_b.data\n",
    "        \n",
    "        return bloom_union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a set of 1000 unique random strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "while len(words) < 1000:\n",
    "    word = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(10))\n",
    "    if word not in words:\n",
    "        words.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's plot the ratio of false positives as we add more words to a BloomFilter, especially as we go beyond its capacity. We will create a BloomFilter with a capacity of 500. We will insert 700 words and use th 300 remaining ones as a test set to calculate the false positives rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = BloomFilter(500)\n",
    "fp = []\n",
    "for i in range(700):\n",
    "    bf.add(words[i])\n",
    "    falses = 0\n",
    "    for j in range(700, 1000):\n",
    "        if words[j] in bf:\n",
    "            falses = falses + 1\n",
    "    fp.append(falses/300 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('inserted words')\n",
    "ax.set_ylabel('% of false positives (test set)')\n",
    "ax.axvline(x = 500, color = 'r')\n",
    "ax.grid(True)\n",
    "plt.plot(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
