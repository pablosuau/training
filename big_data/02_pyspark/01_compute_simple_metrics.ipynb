{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session = SparkSession.builder.appName('simple_statistics').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark_session.read.csv('data/googleplaystore.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the data\n",
    "\n",
    "Firstly, I take a look at the data to familiarise with it. It seems that all the variables are categorical, even though I was expecting some of them to be numerical (like size, installs or rating). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('Category').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rating is stored as a astring. Some non-numerical values\n",
    "df.select('Rating').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a foreign key that points at another table\n",
    "df.select('Reviews').collect()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As strings, with a suffix which indicates the unit\n",
    "df.select('Size').collect()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another categorical variable, instead of numerical, as I first expected\n",
    "df.select('Installs').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('Type').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another variable which I expected to be numerical\n",
    "df.select('Price').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('Content rating').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.select('Genres').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('Last updated').collect()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('Current ver').collect()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('Android ver').distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising proportion of missing values per column\n",
    "\n",
    "The only columns with missing values are `Content Rating`, `Current Ver` and `Android Ver`. However. the proportion of missing values is very low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df.count()\n",
    "for c in df.columns:\n",
    "    print(c)\n",
    "    missing = df.filter(F.col(c).isNull()).count()\n",
    "    print(str(missing/total*100) + '%')\n",
    "    \n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency tables for the categorical variables\n",
    "\n",
    "I am doing this only for the columns that I consider to be categorical in this dataset: `Category`, `Rating`, `Installs`, `Type`, `Content Rating`, `Genres` and `Android ver`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for c in ['Category', 'Rating', 'Installs', 'Type', 'Content Rating', 'Android Ver']:\n",
    "    df.groupby(c).count().sort(F.col('count').desc()).show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Genres` column has to be split by `;`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    F.posexplode(F.split('Genres', ';')).alias('pos', 'val')\n",
    ").groupby('val').count().sort(F.col('count').desc()).show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics for the numerical variables\n",
    "\n",
    "This step requires that the values are parsed and transformed into numerical values. I will do this step for `Rating`, `Reviews` and `Size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = df.select(df.Rating.cast('float').alias('Rating'))\\\n",
    "           .where(F.col('Rating').isNotNull())\\\n",
    "           .where(F.isnan(F.col('Rating')) == False)\n",
    "mean = rating.select(F.mean(rating.Rating).alias('mean')).collect()[0]['mean']\n",
    "std = rating.select(F.stddev(rating.Rating).alias('mean')).collect()[0]['mean']\n",
    "min_ = rating.select(F.min(rating.Rating).alias('min')).collect()[0]['min']\n",
    "max_ = rating.select(F.max(rating.Rating).alias('max')).collect()[0]['max']\n",
    "print('Rating: mean = ' + str(mean) + ', std = ' + str(std))\n",
    "print('min = ' + str(min_) + ', max = ' + str(max_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_histogram = rating.select('Rating').rdd.flatMap(lambda x: x).histogram(10)\n",
    "\n",
    "pd.DataFrame(\n",
    "    list(zip(*rating_histogram)), \n",
    "    columns=['bin', 'frequency']\n",
    ").set_index(\n",
    "    'bin'\n",
    ").plot(kind = 'bar', logy = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df.select(df.Reviews.cast('float').alias('Reviews'))\\\n",
    "            .where(F.col('Reviews').isNotNull())\\\n",
    "            .where(F.isnan(F.col('Reviews')) == False)\n",
    "mean = reviews.select(F.mean(reviews.Reviews).alias('mean')).collect()[0]['mean']\n",
    "std = reviews.select(F.stddev(reviews.Reviews).alias('mean')).collect()[0]['mean']\n",
    "min_ = reviews.select(F.min(reviews.Reviews).alias('min')).collect()[0]['min']\n",
    "max_ = reviews.select(F.max(reviews.Reviews).alias('max')).collect()[0]['max']\n",
    "print('Reviews: mean = ' + str(mean) + ', std = ' + str(std))\n",
    "print('min = ' + str(min_) + ', max = ' + str(max_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_histogram = reviews.select('Reviews').rdd.flatMap(lambda x: x).histogram(10)\n",
    "\n",
    "pd.DataFrame(\n",
    "    list(zip(*reviews_histogram)), \n",
    "    columns=['bin', 'frequency']\n",
    ").set_index(\n",
    "    'bin'\n",
    ").plot(kind = 'bar', logy = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the case of the size, I've observed that the first rows end in M. Are there any other characters?\n",
    "df.select('Size').filter(~df.Size.rlike('[M]')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('Size').filter(df.Size != 'Varies with device').filter(~df.Size.rlike('[Mk]')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering and transforming to numbers\n",
    "filter_strings = ['Varies with device', 'HEALTH_AND_FITNESS', '1,000+']\n",
    "\n",
    "char_replace = F.udf(lambda x: x.replace('M', '').replace('K', ''))\n",
    "\n",
    "sizes = df.select('Size') \\\n",
    "          .filter(df.Size.isin(filter_strings) == False) \\\n",
    "          .withColumn('Size', char_replace('Size').cast('float'))\n",
    "mean = sizes.select(F.mean(sizes.Size).alias('mean')).collect()[0]['mean']\n",
    "std = sizes.select(F.stddev(sizes.Size).alias('mean')).collect()[0]['mean']\n",
    "min_ = sizes.select(F.min(sizes.Size).alias('min')).collect()[0]['min']\n",
    "max_ = sizes.select(F.max(sizes.Size).alias('max')).collect()[0]['max']\n",
    "print('Sizes: mean = ' + str(mean) + ', std = ' + str(std))\n",
    "print('min = ' + str(min_) + ', max = ' + str(max_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes_histogram = sizes.select('Size').rdd.flatMap(lambda x: x).histogram(10)\n",
    "\n",
    "pd.DataFrame(\n",
    "    list(zip(*sizes_histogram)), \n",
    "    columns=['bin', 'frequency']\n",
    ").set_index(\n",
    "    'bin'\n",
    ").plot(kind = 'bar', logy = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would the rating histograms be if we grouped by `Category`? (only the 5 most frequent ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categories = ['FAMILY', 'GAME', 'TOOLS', 'MEDICAL', 'BUSINESS']\n",
    "\n",
    "df_rating = df.where(F.col('Category').isin(categories)) \\\n",
    "              .withColumn('Rating', df.Rating.cast('float')) \\\n",
    "              .where(F.col('Reviews').isNotNull()) \\\n",
    "              .where(F.isnan(F.col('Reviews')) == False) \\\n",
    "              .cache()\n",
    "\n",
    "for c in categories:\n",
    "    histogram = df_rating.filter(df.Category == c) \\\n",
    "                         .select('Rating') \\\n",
    "                         .rdd \\\n",
    "                         .flatMap(lambda x: x) \\\n",
    "                         .histogram([0, 1, 2, 3, 4, 5])\n",
    "\n",
    "    pd.DataFrame(\n",
    "        list(zip(*histogram)), \n",
    "        columns=['rating', c]\n",
    "    ).set_index(\n",
    "        'rating'\n",
    "    ).plot(kind = 'bar', logy = True);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
