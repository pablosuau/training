{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the toy datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_polynomial_dataset(coeffs, width, samples, samples_on_edge):\n",
    "    def _calculate_value(x_i):\n",
    "        return np.sum(np.multiply(np.power(np.repeat(x_i, len(coeffs)), range(len(coeffs))), coeffs))\n",
    "    \n",
    "    x = np.linspace(-10, 10, 100)\n",
    "    boundary = [_calculate_value(x_i) for x_i in x]\n",
    "    margin_1 = [b + width for b in boundary]\n",
    "    margin_2 = [b - width for b in boundary] \n",
    "    \n",
    "    plt.plot(x, boundary, 'r')\n",
    "    plt.plot(x, margin_1, 'r', alpha = 0.3)\n",
    "    plt.plot(x, margin_2, 'r', alpha = 0.3)\n",
    "    \n",
    "    # Generate observations on the edge of the margin\n",
    "    x_1 = []\n",
    "    while len(x_1) < samples_on_edge:\n",
    "        value = np.random.uniform(-10, 10)\n",
    "        x_1.append([value, _calculate_value(value) + width])\n",
    "    value = np.random.uniform(-10, 10)\n",
    "    x_2 = [[value, _calculate_value(value) - width]]\n",
    "    # Generate the rest of the observations\n",
    "    while len(x_1) < samples or len(x_2) < samples:\n",
    "        value_x = np.random.uniform(-10, 10)\n",
    "        value_y = np.random.uniform(min(margin_2), max(margin_1))\n",
    "        if value_y > _calculate_value(value_x) + width:\n",
    "            x_1.append([value_x, value_y])\n",
    "        elif value_y < _calculate_value(value_x) - width:\n",
    "            x_2.append([value_x, value_y])\n",
    "\n",
    "    # Output label\n",
    "    y = np.concatenate((np.repeat(-1, len(x_1)), np.repeat(1, len(x_2))))\n",
    "\n",
    "    # Final version of the dataset\n",
    "    x_1.extend(x_2)\n",
    "    dataset = np.array(x_1)\n",
    "    dataset = np.concatenate((dataset, y[:, None]), axis = 1)\n",
    "\n",
    "    _ = plt.plot(dataset[np.where(dataset[:, 2] == -1), 0], \n",
    "                 dataset[np.where(dataset[:, 2] == -1), 1], \n",
    "                 'o',\n",
    "                 color = 'tab:blue')\n",
    "    _ = plt.plot(dataset[np.where(dataset[:, 2] == 1), 0], \n",
    "                 dataset[np.where(dataset[:, 2] == 1), 1],\n",
    "                 'o',\n",
    "                 color = 'tab:orange')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = generate_polynomial_dataset([-3, 1.7], 2, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = generate_polynomial_dataset([1, -2.3], 3, 15, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_3 = generate_polynomial_dataset([0.2, -0.5, 0.3, 0.08, -0.003], 5, 40, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gaussian_dataset(params, width, samples, samples_on_edge):\n",
    "    # Not really gaussian data, but a toydataset design to be \n",
    "    # used with a RBF kernel\n",
    "    x = np.linspace(-10, 10, 500)\n",
    "    y = np.linspace(-10, 10, 500)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    \n",
    "    @np.vectorize\n",
    "    def border(x, y, w):\n",
    "        close = []\n",
    "        border = []\n",
    "        for p in range(len(params)):\n",
    "            dist = math.sqrt((params[p][0] - x) ** 2 + (params[p][1] - y) ** 2)\n",
    "            close.append(dist < params[p][2] - w)\n",
    "            border.append(dist == params[p][2] - w)\n",
    "        if np.any(border) and np.all(np.logical_not(close)):\n",
    "            return 0\n",
    "        elif np.any(close):\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "    plt.contour(xv, yv, border(xv, yv, 0), levels = [0], colors = ['r'])\n",
    "    c = plt.contour(xv, yv, border(xv, yv, width), levels = [0], colors = ['r'], alpha = 0.3)\n",
    "    plt.contour(xv, yv, border(xv, yv, -width), levels = [0], colors = ['r'], alpha = 0.3)\n",
    "    \n",
    "    x_1 = []\n",
    "    for i in range(len(c.collections[0].get_paths())):\n",
    "        v = c.collections[0].get_paths()[i].vertices\n",
    "        indices = list(range(v.shape[0]))\n",
    "        np.random.shuffle(indices)\n",
    "        x_1.extend([[v[j, 0], v[j, 1]] for j in indices[:samples_on_edge]])\n",
    "    x_2 = [] \n",
    "    while len(x_1) < samples and len(x_2) < samples:\n",
    "        value_x = np.random.uniform(-10, 10)\n",
    "        value_y = np.random.uniform(-10, 10)\n",
    "        close = False\n",
    "        margin = False\n",
    "        for p in range(len(params)):\n",
    "            dist = math.sqrt((params[p][0] - value_x) ** 2 + (params[p][1] - value_y) ** 2)\n",
    "            if dist < params[p][2]:\n",
    "                close = True\n",
    "            if dist > params[p][2] - width and dist < params[p][2] + width:\n",
    "                margin = True\n",
    "        if not margin:\n",
    "            if close:\n",
    "                x_1.append([value_x, value_y])\n",
    "            else:\n",
    "                x_2.append([value_x, value_y])\n",
    "            \n",
    "     # Output label\n",
    "    y = np.concatenate((np.repeat(-1, len(x_1)), np.repeat(1, len(x_2))))\n",
    "\n",
    "    # Final version of the dataset\n",
    "    x_1.extend(x_2)\n",
    "    dataset = np.array(x_1)\n",
    "    dataset = np.concatenate((dataset, y[:, None]), axis = 1)\n",
    "\n",
    "    _ = plt.plot(dataset[np.where(dataset[:, 2] == -1), 0], \n",
    "                 dataset[np.where(dataset[:, 2] == -1), 1], \n",
    "                 'o',\n",
    "                 color = 'tab:blue')\n",
    "    _ = plt.plot(dataset[np.where(dataset[:, 2] == 1), 0], \n",
    "                 dataset[np.where(dataset[:, 2] == 1), 1],\n",
    "                 'o',\n",
    "                 color = 'tab:orange')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = [[2, 3, 6],\n",
    "          [-2, -4, 3],\n",
    "          [-9, 7.5, 3]]\n",
    "\n",
    "dataset_4 = generate_gaussian_dataset(params, 0.3, 100, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential minimal optimisation\n",
    "\n",
    "This is an implementation of Platt's paper: \"Sequential Minimal Optimisation: a fast algorithm for training Support Vector machines\".\n",
    "\n",
    "I am simplifying my implementation by not implementing an error cache. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMO:\n",
    "    def __init__(self, X, y, C, tol = 0.01, eps = 0.01, kernel = 'linear', kernel_params = None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.C = C\n",
    "        self.tol = tol\n",
    "        self.eps = eps\n",
    "        self.kernel = kernel\n",
    "        self.kernel_params = kernel_params\n",
    "        \n",
    "    def _kernel(self, xi, xj):\n",
    "        if self.kernel == 'linear':\n",
    "            return np.dot(xi, xj)\n",
    "        elif self.kernel == 'poly':\n",
    "            return (self.kernel_params[0] * np.dot(xi, xj) + self.kernel_params[1]) ** self.kernel_params[2]\n",
    "        elif self.kernel == 'rbf':\n",
    "            return math.exp(-self.kernel_params[0] * np.sum(np.power(xi - xj, 2)))\n",
    "        \n",
    "    def _svm_output(self, x):\n",
    "        u = 0\n",
    "        for i in range(self.X.shape[0]):\n",
    "            u = u + self.y[i] * self.alpha[i] * self._kernel(self.X[i, :], x)\n",
    "        return u - self.b\n",
    "        \n",
    "    def _objective_function(self):\n",
    "        psi = 0\n",
    "        for i in range(self.X.shape[0]):\n",
    "            for j in range(self.X.shape[0]):\n",
    "                psi = psi + self.y[i] * self.y[j] * self._kernel(self.X[i, :], self.X[j, :]) * self.alpha[i] * self.alpha[j]\n",
    "\n",
    "        return 0.5 * psi - np.sum(self.alpha)\n",
    "\n",
    "    def _take_step(self, i1, i2, E2, alph2):\n",
    "        if i1 == i2:\n",
    "            return 0\n",
    "\n",
    "        alph1 = self.alpha[i1]\n",
    "        y1 = self.y[i1]\n",
    "        y2 = self.y[i2]\n",
    "        E1 = self._svm_output(self.X[i1, :]) - y1\n",
    "        s = y1 * y2\n",
    "\n",
    "        # compute L, H via equations (13) and (14)\n",
    "        if y1 != y2:\n",
    "            L = max(0, alph2 - alph1)\n",
    "            H = min(self.C, self.C + alph2 - alph1)\n",
    "        else:\n",
    "            L = max(0, alph2 + alph1 - self.C)\n",
    "            H = min(self.C, alph2 + alph1)\n",
    "        if L == H:\n",
    "            return 0\n",
    "\n",
    "        k11 = self._kernel(self.X[i1, :], self.X[i1, :])\n",
    "        k12 = self._kernel(self.X[i1, :], self.X[i2, :])\n",
    "        k22 = self._kernel(self.X[i2, :], self.X[i2, :])\n",
    "        eta = k11 + k22 - 2 * k12\n",
    "\n",
    "        if eta > 0:\n",
    "            a2 = alph2 + y2 * (E1 - E2) / eta\n",
    "            if a2 < L:\n",
    "                a2 = L\n",
    "            elif a2 > H:\n",
    "                a2 = H\n",
    "        else:\n",
    "            prev_alph2 = self.alpha[i2]\n",
    "            self.alpha[i2] = L\n",
    "            L_obj = self._objective_function()\n",
    "            self.alpha[i2] = H\n",
    "            H_obj = self._objective_function()\n",
    "            self.alpha[i2] = prev_alph2\n",
    "\n",
    "            if L_obj < H_obj - self.eps:\n",
    "                a2 = L\n",
    "            elif L_obj > H_obj + self.eps:\n",
    "                a2 = H\n",
    "            else:\n",
    "                a2 = alph2\n",
    "\n",
    "        if math.fabs(a2 - alph2) < self.eps * (a2 + alph2 + self.eps):\n",
    "            return 0\n",
    "\n",
    "        a1 = alph1 + s * (alph2 - a2)\n",
    "\n",
    "        # Update threshold to reflect chang in lagrance multipliers\n",
    "        new_b1 = E1 + y1 * (a1 - self.alpha[i1]) * k11 + y2 * (a2 - self.alpha[i2]) * k12 + self.b\n",
    "        new_b2 = E2 + y1 * (a1 - self.alpha[i1]) * k12 + y2 * (a2 - self.alpha[i2]) * k22 + self.b\n",
    "\n",
    "        if a1 < 0 or a1 > self.C:\n",
    "            self.b = new_b1\n",
    "        elif a2 < 0 or a2 > self.C:\n",
    "            self.b = new_b2\n",
    "        else:\n",
    "            self.b = (new_b1 + new_b2) / 2.0\n",
    "\n",
    "        self.alpha[i1] = a1\n",
    "        self.alpha[i2] = a2\n",
    "\n",
    "        return 1\n",
    "\n",
    "    def _examine_example(self, i2):\n",
    "        y2 = self.y[i2]\n",
    "        alph2 = self.alpha[i2]\n",
    "        E2 = self._svm_output(self.X[i2, :]) - y2\n",
    "        r2 = E2 * y2\n",
    "\n",
    "        if (r2 < -self.tol and alph2 < self.C) or (r2 > self.tol and alph2 > 0):\n",
    "            if np.sum(np.logical_and(self.alpha != 0, self.alpha != self.C)) > 1:\n",
    "                # i1 chosen among the indices that violate the KKT conditions\n",
    "                i1 = random.randint(0, len(self.alpha) - 1)\n",
    "                loop = 0\n",
    "                while loop < len(self.alpha):\n",
    "                    if not((self.alpha[i1] == 0 and self.y[i1] * self._svm_output(self.X[i1, :]) >= 1) or \\\n",
    "                           (self.alpha[i1] > 0 and self.alpha[i1] < self.C and \\\n",
    "                            self.y[i1] * self._svm_output(self.X[i2, :]) == 1) or \\\n",
    "                           (self.alpha[i1] == self.C and self.y[i1] * self._svm_output(self.X[i1, :]) <= 1)):\n",
    "                            if self._take_step(i1, i2, E2, alph2):\n",
    "                                return 1\n",
    "\n",
    "                    loop = loop + 1\n",
    "                    i1 = (i1 + 1) % len(self.alpha)\n",
    "\n",
    "            # Loop over all non-zero and non-C alpha, starting at a randompoint\n",
    "            indices = np.where(np.logical_and(self.alpha != 0, self.alpha != self.C))[0]\n",
    "            if len(indices) > 0:\n",
    "                i = random.randint(0, len(indices) - 1)\n",
    "                loop = 0\n",
    "                while loop < len(indices):\n",
    "                    i1 = indices[i]\n",
    "                    if self._take_step(i1, i2, E2, alph2):\n",
    "                        return 1\n",
    "\n",
    "                    loop = loop + 1\n",
    "                    i = (i + 1) % len(indices)        \n",
    "\n",
    "            # Loop over all possible i1, starting at a random point\n",
    "            i1 = random.randint(0, len(self.alpha) - 1)\n",
    "            loop = 0\n",
    "            while loop < len(self.alpha):\n",
    "                if self._take_step(i1, i2, E2, alph2):\n",
    "                    return 1\n",
    "\n",
    "                loop = loop + 1\n",
    "                i1 = (i1 + 1) % len(self.alpha)\n",
    "\n",
    "        return 0\n",
    "        \n",
    "    def fit(self):\n",
    "        # Alphas have to be initialised to zero: \n",
    "        # https://stats.stackexchange.com/questions/363952/why-do-svms-using-smo-algorithm-work-only-when-the-initial-values-of-the-multipl\n",
    "        self.alpha = np.zeros(self.X.shape[0], )\n",
    "        self.b = 0\n",
    "\n",
    "        num_changed = 0\n",
    "        examine_all = 1\n",
    "        while num_changed > 0 or examine_all:\n",
    "            num_changed = 0\n",
    "            if examine_all:\n",
    "                for i in range(self.X.shape[0]):\n",
    "                    num_changed = num_changed + self._examine_example(i)\n",
    "            else:\n",
    "                for i in range(self.X.shape[0]):\n",
    "                    if self.alpha[i] != 0 and self.alpha[i] != self.C:\n",
    "                        num_changed = num_changed + self._examine_example(i)\n",
    "            if examine_all == 1:\n",
    "                examine_all = 0\n",
    "            elif num_changed == 0:\n",
    "                examine_all = 1 \n",
    "                \n",
    "    def predict(self, X_test):\n",
    "        y = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            y.append(int(self._svm_output(X_test[i, :]) > 0))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(dataset, smo):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    fig.set_figwidth(16)\n",
    "    \n",
    "    # Left side\n",
    "    _ = ax[0].plot(dataset[np.where(dataset[:, 2] == -1), 0], \n",
    "                   dataset[np.where(dataset[:, 2] == -1), 1], \n",
    "                   'o',\n",
    "                   color = 'tab:blue')\n",
    "    _ = ax[0].plot(dataset[np.where(dataset[:, 2] == 1), 0], \n",
    "                   dataset[np.where(dataset[:, 2] == 1), 1],\n",
    "                   'o',\n",
    "                   color = 'tab:orange')\n",
    "    \n",
    "    # highlight the support vectors\n",
    "    index = np.where(smo.alpha != 0)[0]\n",
    "    _ = ax[0].plot(dataset[index, 0], \n",
    "                   dataset[index, 1], \n",
    "                   'o', \n",
    "                   markerSize = 10, \n",
    "                   markerfacecolor = 'None',\n",
    "                   markeredgecolor = 'red',\n",
    "                   markeredgewidth = 2)\n",
    "    \n",
    "    y_lim = ax[0].get_ylim()\n",
    "    yy = list(np.linspace(y_lim[0], y_lim[1], 100))\n",
    "    x_lim = ax[0].get_xlim()\n",
    "    xx = list(np.linspace(x_lim[0], x_lim[1], 100))\n",
    "    \n",
    "    colormap = plt.cm.RdYlBu\n",
    "    res = np.zeros((len(xx), len(yy)))\n",
    "    for i in range(len(yy)):\n",
    "        for j in range(len(xx)):\n",
    "            x_test = np.array([xx[j], yy[i]]).reshape(-1, 1).T\n",
    "            res[i, j] = smo.predict(x_test)[0]\n",
    "    ext = [x_lim[0], x_lim[1], y_lim[0], y_lim[1]]\n",
    "    ax[0].imshow(res, zorder = 0, extent = ext, alpha = 0.5, cmap = colormap, origin = 'lower', aspect = 'auto')\n",
    "    \n",
    "    # Right side\n",
    "    indexes = np.argsort(-smo.alpha)\n",
    "    ax[1].bar(range(len(smo.alpha)), smo.alpha[indexes])\n",
    "    ax[1].set_title('alpha values - in descending order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_svm(dataset):\n",
    "    #smo = SMO(X = dataset[:, :2], y = dataset[:, 2], C = 1)\n",
    "    smo = SMO(X = dataset[:, :2], y = dataset[:, 2], C = 1, kernel = 'poly', kernel_params = [0.1, 3, 2])\n",
    "    #smo = SMO(X = dataset[:, :2], y = dataset[:, 2], C = 1, kernel = 'rbf', kernel_params = [0.5])\n",
    "    smo.fit()\n",
    "    \n",
    "    plot_predictions(dataset, smo)\n",
    "    \n",
    "    mse =  np.sum(np.power(smo.predict(dataset[:, :2]) - dataset[:, 2], 2))\n",
    "    print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_fitting(dataset):\n",
    "    param1 = np.arange(0, 3.2, 0.2)\n",
    "    param2 = np.arange(0, 3.2, 0.2)\n",
    "    param3 = np.arange(0, 3.2, 0.2)\n",
    "    best_mse = sys.maxsize\n",
    "    \n",
    "    if os.path.exists('polynomial.chk'):\n",
    "        results = pd.read_csv('polynomial.chk')\n",
    "    else:\n",
    "        results = pd.DataFrame(columns = ['p1', 'p2', 'p3', 'mse'])\n",
    "        \n",
    "    i = 0\n",
    "    for p1 in param1:\n",
    "        for p2 in param2:\n",
    "            for p3 in param3:\n",
    "                if i >= len(results):\n",
    "                    smo = SMO(X = dataset[:, :2], y = dataset[:, 2], C = 1, kernel = 'poly', kernel_params = [p1, p2, p3])\n",
    "                    smo.fit()\n",
    "                    mse =  np.sum(np.power(smo.predict(dataset[:, :2]) - dataset[:, 2], 2))\n",
    "\n",
    "                    print((p1, p2, p3, mse))\n",
    "                    \n",
    "                    results.loc[len(results)] = {'p1': p1, 'p2': p2, 'p3': p3, 'mse':mse}\n",
    "                    results.to_csv('polynomial.chk', index = False)\n",
    "                i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = polynomial_fitting(dataset_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test_svm(dataset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test_svm(dataset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_svm(dataset_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_svm(dataset_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "np.sum(np.power(a - b, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: probar diferentes parametros kernels para ejemplos especificos de ellos (probar lineal con todos)\n",
    "# Cambiar colores de fondo azul/naranja\n",
    "# Falta comprobar efecto primer parametro de polynomial, y jugar con el segundo un poco todavia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
