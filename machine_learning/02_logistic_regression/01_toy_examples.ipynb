{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I apply logistic regression to two toy examples. My objective is to have a better understanding of the Newton-Raphson method for optimisation, used to fit a logistic regression model. \n",
    "\n",
    "## 1D example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/logistic_regression_1d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(data[data.y == 0].x, data[data.y == 0].y, 'o')\n",
    "ax.plot(data[data.y == 1].x, data[data.y == 1].y, 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to fit a model in the following form:\n",
    "\n",
    "$\\text{logit}(y) = \\beta_0 + \\beta_1 x$\n",
    "\n",
    "where $\\text{logit}(y) = \\text{ln}\\left(\\frac{y}{1 - y}\\right)$, and therefore $y = \\frac{e^{\\beta_0 + \\beta_1 x_{1,i} + \\ldots + \\beta_{k} x_{k,i}}}{1 + e^{\\beta_0 + \\beta_1 x_{1,i} + \\ldots + \\beta_{k} x_{k,i}}}$\n",
    "\n",
    "We do this by applying iteratively reweighted least squares, which form is obtained after derivation based on the Newton-Raphson's method (see https://www.cs.cmu.edu/~mgormley/courses/10701-f16/slides/lecture5.pdf):\n",
    "\n",
    "$\\vec{\\beta}_{n+1} = \\vec{\\beta}_n - \\left(X^TSX\\right)^{-1}\\left(X^T(\\mu - y)\\right)$\n",
    "\n",
    "where $S = \\text{diag}(\\mu_i(1 - \\mu_i))$ is a diagonal matrix of weights and each weight is calculated as $\\mu_i = 1/(1+e^{-\\left(\\beta_0 + \\beta_1 x_{1,i} + \\ldots + \\beta_{k} x_{k,i}\\right)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logistic(x, y):\n",
    "    '''\n",
    "    Fits a logistic regression model. X and y should be m x n arrays, where m is the number\n",
    "    of observartaions and n is the number of features\n",
    "    '''\n",
    "    X =  np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "    B = np.zeros((X.shape[1], 1))\n",
    "    B[0] = math.log(np.mean(y) / (1 - np.mean(y)))\n",
    "    prev_B = B + 1\n",
    "    \n",
    "    while np.sum(np.abs(B - prev_B)) > 0.001:\n",
    "        prev_B = B\n",
    "        \n",
    "        mu = 1 / (1 + np.exp(-np.dot(X, B)))\n",
    "        S = np.diag((mu * (1 - mu)).flatten())\n",
    "        B = B - np.dot(np.linalg.inv(np.dot(np.dot(X.T, S), X)), np.dot(X.T, mu - y))\n",
    "        print(B)\n",
    "        \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "B = fit_logistic(data.x.values.reshape(-1, 1), data.y.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(data[data.y == 0].x, data[data.y == 0].y, 'o')\n",
    "ax.plot(data[data.y == 1].x, data[data.y == 1].y, 'o')\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "for x in np.arange(data.x.min() - 1, data.x.max() + 1, 0.1):\n",
    "    y = math.exp(B[0] + B[1] * x) / (1 + math.exp(B[0] + B[1] * x))\n",
    "    xs.append(x)\n",
    "    ys.append(y)\n",
    "ax.plot(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions to show a confusion matrix\n",
    "data['p'] = data['x'].apply(lambda x: math.exp(B[0] + B[1] * x) / (1 + math.exp(B[0] + B[1] * x)))\n",
    "data['y_pred'] = data['p'].apply(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "data.groupby(['y', 'y_pred'])['x'].count().reset_index().pivot(index = 'y', columns = 'y_pred', values = 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/logistic_regression_2d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = fit_logistic(data[['Age', 'EstimatedSalary']].values, data.Purchased.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
