{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, y, coef) = make_regression(n_samples = SAMPLES, \n",
    "                               n_features = 6, \n",
    "                               n_informative = 6, \n",
    "                               effective_rank = 2,\n",
    "                               n_targets = 1, \n",
    "                               coef = True,\n",
    "                               bias = 3,\n",
    "                               tail_strength = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47.93845494, 60.57119573, 63.74622774, 72.78881584, 81.19385617,\n",
       "       11.56618719])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\displaystyle \\min_{\\beta}\\frac{1}{n}||y-X\\beta||^2_{2}+\\lambda||\\beta||_1 + \\mu||\\beta||_2^2$\n",
    "\n",
    "$L=\\frac{1}{n}\\displaystyle\\sum_{i=1}^{n}\\left(y_i - \\left(\\beta_0 + \\displaystyle\\sum_{j=1}^{6} \\beta_j x_{ij}\\right)\\right)^2 + \\lambda\\displaystyle\\sum_{j=0}^{6}|\\beta_j| + \\mu\\displaystyle\\sum_{j=0}^{6} \\beta_j^2$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial \\beta_0} = \\frac{1}{n}\\displaystyle\\sum_{i=1}^{n}\\left(2\\beta_0 + \\displaystyle\\sum_{j=1}^6\\beta_0\\beta_j-y_i\\right) + \\lambda\\frac{\\beta_0}{|\\beta_0|} + 2\\mu\\beta_0$\n",
    "\n",
    "And for any $k|k\\neq0|$, and for $\\beta_k\\neq 0$:\n",
    "\n",
    "$\\frac{\\partial L}{\\partial \\beta_{k}} = \\frac{1}{n}\\displaystyle\\sum_{i=1}^{n}\\left(2\\beta_k + \\displaystyle\\sum_{j|j\\neq k}^6\\beta_k\\beta_j-y_i\\right) + \\lambda\\frac{\\beta_k}{|\\beta_k|} + 2\\mu\\beta_k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function for backtracking line search\n",
    "def line_search(current_params, gradient, beta):\n",
    "    current_params = np.array(current_params)\n",
    "    \n",
    "    def _f(params):\n",
    "        b = np.power(params, 4) - 16 * np.power(params, 2) + 5 * np.array(params)\n",
    "        yp = 0.5 * np.dot(xp, b)\n",
    "        return np.mean(np.power(y - yp, 2), axis = 0)\n",
    "        \n",
    "    t = 1.0\n",
    "    while _f(current_params - t * gradient) > _f(current_params) - \\\n",
    "                                              t/2.0 * norm(gradient, ord = 2) ** 2:\n",
    "        t = t * beta\n",
    "        \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Auxiliary function to calculate gradient\n",
    "def calculate_gradient(x, y, current_params):\n",
    "    \n",
    "\n",
    "    return [d_b1, d_b2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
