{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import fabs\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = 10000 # This is not enough data for such high dimensionality - the model is going to be biased\n",
    "DIVERGENCE_VALUE = 10\n",
    "MAX_ITERATIONS = 10 ** 5\n",
    "STOP_THRESHOLD = 10 ** -10\n",
    "DIMENSIONS = 7\n",
    "LAMBDA = 0.01\n",
    "MU = 0.0001\n",
    "ALPHA = 0.5\n",
    "BETA = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, y, coef) = make_regression(n_samples = SAMPLES, \n",
    "                               n_features = DIMENSIONS - 1, \n",
    "                               n_informative = DIMENSIONS - 1, \n",
    "                               effective_rank = 2,\n",
    "                               n_targets = 1, \n",
    "                               coef = True,\n",
    "                               bias = 3,\n",
    "                               tail_strength = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([75.78410261, 21.72818777, 75.92203362, 56.5729803 , 77.78913092,\n",
       "       18.43607803])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\displaystyle \\min_{\\beta}\\frac{1}{n}||y-X\\beta||^2_{2}+\\lambda||\\beta||_1 + \\mu||\\beta||_2^2$\n",
    "\n",
    "$L=\\frac{1}{n}\\displaystyle\\sum_{i=1}^{n}\\left(y_i - \\left(\\beta_0 + \\displaystyle\\sum_{j=1}^{6} \\beta_j x_{ij}\\right)\\right)^2 + \\lambda\\displaystyle\\sum_{j=0}^{6}|\\beta_j| + \\mu\\displaystyle\\sum_{j=0}^{6} \\beta_j^2$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial \\beta_0} = -\\frac{2}{n}\\displaystyle\\sum_{i=1}^{n}\\left(y_i - \\beta_0 -\\displaystyle\\sum_{j=1}^{6} \\beta_j x_{ij}\\right) + \\lambda\\frac{\\beta_0}{|\\beta_0|} + 2\\mu\\beta_0$\n",
    "\n",
    "And for $\\beta_{k\\neq 0}$:\n",
    "\n",
    "$\\frac{\\partial L}{\\partial \\beta_{k}} = -\\frac{2}{n}\\displaystyle\\sum_{i=1}^{n}x_{ik}\\left(y_i - \\beta_0 -\\displaystyle\\sum_{j=1}^{6} \\beta_j x_{ij}\\right) + \\lambda\\frac{\\beta_k}{|\\beta_k|} + 2\\mu\\beta_k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, y, coef) = make_regression(n_samples = SAMPLES, \n",
    "                               n_features = DIMENSIONS - 1, \n",
    "                               n_informative = DIMENSIONS - 1, \n",
    "                               effective_rank = 2,\n",
    "                               n_targets = 1, \n",
    "                               coef = True,\n",
    "                               bias = 3,\n",
    "                               tail_strength = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((np.ones((SAMPLES, 1)), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function to calculate gradient\n",
    "# l = lambda\n",
    "# m = mu\n",
    "def calculate_gradient(x, y, l, m, current_params):\n",
    "    db = np.zeros(DIMENSIONS)    \n",
    "    \n",
    "    # Common term\n",
    "    common = (y - \n",
    "              current_params[0] - \n",
    "              np.sum(np.multiply(np.tile(current_params[1:], (SAMPLES, 1)), x[:, 1:]), axis=1))\n",
    "    \n",
    "    # Function for the regularisation factor\n",
    "    def regularisation(param, l, m):\n",
    "        return l * param / fabs(param) + 2 * m * param\n",
    "    \n",
    "    # db_0\n",
    "    db[0] = - 2 / float(SAMPLES) * np.sum(common) + regularisation(current_params[0], l, m)\n",
    "\n",
    "    # db_k, k != 0\n",
    "    for k in range(1, DIMENSIONS):\n",
    "        db[k] = -2 / float(SAMPLES) * np.sum(np.multiply(x[:, k], common)) + regularisation(current_params[k], l, m)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _loss(params, l, m):\n",
    "        y_pred = np.matmul(X, np.array(params))\n",
    "        L = np.mean(np.power(y - y_pred, 2), axis = 0)\n",
    "        L = L + l * np.sum(np.fabs(params)) + m * np.sum(np.power(params, 2))\n",
    "        return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function for backtracking line search\n",
    "# Not using exact because I would have to do second partial derivatives with respect to t\n",
    "# However, the line backtracking algorithm is very sensitive to alpha, so maybe use the direct\n",
    "# approach for the line algorithm if we can calculate it\n",
    "# Besides, baktracking line search is very slow\n",
    "def line_search(current_params, gradient, beta, l, m):\n",
    "    current_params = np.array(current_params)\n",
    "        \n",
    "    t = 1.0\n",
    "    while _loss(current_params - t * gradient, l, m) > _loss(current_params, l, m) - \\\n",
    "                                                         t * ALPHA * np.matmul(gradient.T, gradient):\n",
    "        t = t * beta\n",
    "        \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Coordinate gradient descent implementation\n",
    "# Cycling through the dimensions\n",
    "def cdg(X, y, current_params, l, m):\n",
    "    w = [np.array(current_params[:])]\n",
    "    it = 0\n",
    "    while it == 0 or (np.sum(np.abs(np.array(current_params) - np.array(w[-1]))) > STOP_THRESHOLD and \\\n",
    "                      np.all(np.array(current_params) - np.array(w[-1]) < DIVERGENCE_VALUE) and \\\n",
    "                      it < MAX_ITERATIONS):\n",
    "        w.append(current_params)\n",
    "        # Select the gradient for the next dimension\n",
    "        d = it % DIMENSIONS\n",
    "        g = np.zeros(DIMENSIONS)\n",
    "        g[d] = calculate_gradient(X, y, l, m, current_params)[d]\n",
    "        # Linear search in the direction of the selected dimension\n",
    "        t = line_search(current_params, g, BETA, l, m)\n",
    "        # Update parameters\n",
    "        current_params = list(np.array(w[-1]) - t * np.array(g))[:]\n",
    "        # Wrapping up the iteration\n",
    "        it = it + 1\n",
    "    w.append(current_params)\n",
    "    \n",
    "    return(it, current_params, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 0.1 as the initial values for the parameters to prevent divisions by zero during gradient calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "it, current_params, w = cdg(X, y, [0.1 for i in range(DIMENSIONS)], LAMBDA, MU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.417889872690914e-32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_loss([3] + list(coef), 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9682244188548642"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_loss(current_params, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.29099479672584"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_loss([0.1 for i in range(DIMENSIONS)], 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 4.000e+00, 9.000e+00, 1.800e+01, 6.500e+01, 1.580e+02,\n",
       "        3.430e+02, 6.590e+02, 9.910e+02, 1.350e+03, 1.577e+03, 1.543e+03,\n",
       "        1.199e+03, 9.090e+02, 6.210e+02, 3.410e+02, 1.210e+02, 5.900e+01,\n",
       "        2.500e+01, 7.000e+00]),\n",
       " array([-4.21962916, -3.83340564, -3.44718211, -3.06095858, -2.67473505,\n",
       "        -2.28851153, -1.902288  , -1.51606447, -1.12984094, -0.74361742,\n",
       "        -0.35739389,  0.02882964,  0.41505317,  0.80127669,  1.18750022,\n",
       "         1.57372375,  1.95994728,  2.3461708 ,  2.73239433,  3.11861786,\n",
       "         3.50484139]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.matmul(X, np.array(current_params)) - np.matmul(X, np.array([3] + list(coef))), bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 75.78410261068944,\n",
       " 21.728187771684905,\n",
       " 75.92203361699748,\n",
       " 56.572980297077535,\n",
       " 77.789130921549,\n",
       " 18.436078025540404]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[3] + list(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.9793652143610063,\n",
       " 0.1463822426076789,\n",
       " -3.7577641436975597e-10,\n",
       " 5.43965285393991e-11,\n",
       " 0.1900441673603966,\n",
       " 9.112273627112912e-05,\n",
       " -2.658605311679812e-11]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
