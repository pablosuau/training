{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.read_csv('../../datasets/titanic_training_processed.csv')\n",
    "df_test = pd.read_csv('../../datasets/titanic_test_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>TicketPrefix_A/5</th>\n",
       "      <th>...</th>\n",
       "      <th>CabinClass_C</th>\n",
       "      <th>CabinClass_E</th>\n",
       "      <th>CabinClass_G</th>\n",
       "      <th>CabinClass_D</th>\n",
       "      <th>CabinClass_A</th>\n",
       "      <th>CabinClass_B</th>\n",
       "      <th>CabinClass_F</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.565419</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.502163</td>\n",
       "      <td>0.902081</td>\n",
       "      <td>-0.565368</td>\n",
       "      <td>0.737281</td>\n",
       "      <td>9.380891</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266146</td>\n",
       "      <td>-0.192901</td>\n",
       "      <td>-0.067116</td>\n",
       "      <td>-0.196006</td>\n",
       "      <td>-0.130783</td>\n",
       "      <td>-0.235849</td>\n",
       "      <td>-0.121613</td>\n",
       "      <td>0.618959</td>\n",
       "      <td>-0.481772</td>\n",
       "      <td>-0.30739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.663488</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>0.786404</td>\n",
       "      <td>-1.107304</td>\n",
       "      <td>1.766775</td>\n",
       "      <td>-1.354813</td>\n",
       "      <td>-0.106480</td>\n",
       "      <td>...</td>\n",
       "      <td>3.753114</td>\n",
       "      <td>-0.192901</td>\n",
       "      <td>-0.067116</td>\n",
       "      <td>-0.196006</td>\n",
       "      <td>-0.130783</td>\n",
       "      <td>-0.235849</td>\n",
       "      <td>-0.121613</td>\n",
       "      <td>-1.613803</td>\n",
       "      <td>2.073341</td>\n",
       "      <td>-0.30739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.258192</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.488580</td>\n",
       "      <td>0.902081</td>\n",
       "      <td>-0.565368</td>\n",
       "      <td>-1.354813</td>\n",
       "      <td>-0.106480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266146</td>\n",
       "      <td>-0.192901</td>\n",
       "      <td>-0.067116</td>\n",
       "      <td>-0.196006</td>\n",
       "      <td>-0.130783</td>\n",
       "      <td>-0.235849</td>\n",
       "      <td>-0.121613</td>\n",
       "      <td>0.618959</td>\n",
       "      <td>-0.481772</td>\n",
       "      <td>-0.30739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433068</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>0.420494</td>\n",
       "      <td>-1.107304</td>\n",
       "      <td>1.766775</td>\n",
       "      <td>-1.354813</td>\n",
       "      <td>-0.106480</td>\n",
       "      <td>...</td>\n",
       "      <td>3.753114</td>\n",
       "      <td>-0.192901</td>\n",
       "      <td>-0.067116</td>\n",
       "      <td>-0.196006</td>\n",
       "      <td>-0.130783</td>\n",
       "      <td>-0.235849</td>\n",
       "      <td>-0.121613</td>\n",
       "      <td>0.618959</td>\n",
       "      <td>-0.481772</td>\n",
       "      <td>-0.30739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433068</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.486064</td>\n",
       "      <td>0.902081</td>\n",
       "      <td>-0.565368</td>\n",
       "      <td>0.737281</td>\n",
       "      <td>-0.106480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266146</td>\n",
       "      <td>-0.192901</td>\n",
       "      <td>-0.067116</td>\n",
       "      <td>-0.196006</td>\n",
       "      <td>-0.130783</td>\n",
       "      <td>-0.235849</td>\n",
       "      <td>-0.121613</td>\n",
       "      <td>0.618959</td>\n",
       "      <td>-0.481772</td>\n",
       "      <td>-0.30739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived       Age     SibSp     Parch      Fare  Pclass_3  \\\n",
       "0            1         0 -0.565419  0.432550 -0.473408 -0.502163  0.902081   \n",
       "1            2         1  0.663488  0.432550 -0.473408  0.786404 -1.107304   \n",
       "2            3         1 -0.258192 -0.474279 -0.473408 -0.488580  0.902081   \n",
       "3            4         1  0.433068  0.432550 -0.473408  0.420494 -1.107304   \n",
       "4            5         0  0.433068 -0.474279 -0.473408 -0.486064  0.902081   \n",
       "\n",
       "   Pclass_1  Sex_male  TicketPrefix_A/5     ...      CabinClass_C  \\\n",
       "0 -0.565368  0.737281          9.380891     ...         -0.266146   \n",
       "1  1.766775 -1.354813         -0.106480     ...          3.753114   \n",
       "2 -0.565368 -1.354813         -0.106480     ...         -0.266146   \n",
       "3  1.766775 -1.354813         -0.106480     ...          3.753114   \n",
       "4 -0.565368  0.737281         -0.106480     ...         -0.266146   \n",
       "\n",
       "   CabinClass_E  CabinClass_G  CabinClass_D  CabinClass_A  CabinClass_B  \\\n",
       "0     -0.192901     -0.067116     -0.196006     -0.130783     -0.235849   \n",
       "1     -0.192901     -0.067116     -0.196006     -0.130783     -0.235849   \n",
       "2     -0.192901     -0.067116     -0.196006     -0.130783     -0.235849   \n",
       "3     -0.192901     -0.067116     -0.196006     -0.130783     -0.235849   \n",
       "4     -0.192901     -0.067116     -0.196006     -0.130783     -0.235849   \n",
       "\n",
       "   CabinClass_F  Embarked_S  Embarked_C  Embarked_Q  \n",
       "0     -0.121613    0.618959   -0.481772    -0.30739  \n",
       "1     -0.121613   -1.613803    2.073341    -0.30739  \n",
       "2     -0.121613    0.618959   -0.481772    -0.30739  \n",
       "3     -0.121613    0.618959   -0.481772    -0.30739  \n",
       "4     -0.121613    0.618959   -0.481772    -0.30739  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>TicketPrefix_A/5</th>\n",
       "      <th>TicketPrefix_PC</th>\n",
       "      <th>...</th>\n",
       "      <th>CabinClass_C</th>\n",
       "      <th>CabinClass_E</th>\n",
       "      <th>CabinClass_G</th>\n",
       "      <th>CabinClass_D</th>\n",
       "      <th>CabinClass_A</th>\n",
       "      <th>CabinClass_B</th>\n",
       "      <th>CabinClass_F</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0.394665</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.490508</td>\n",
       "      <td>0.902081</td>\n",
       "      <td>-0.565368</td>\n",
       "      <td>0.737281</td>\n",
       "      <td>-0.10648</td>\n",
       "      <td>-0.268554</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266146</td>\n",
       "      <td>-0.192901</td>\n",
       "      <td>-0.067116</td>\n",
       "      <td>-0.196006</td>\n",
       "      <td>-0.130783</td>\n",
       "      <td>-0.235849</td>\n",
       "      <td>-0.121613</td>\n",
       "      <td>-1.613803</td>\n",
       "      <td>-0.481772</td>\n",
       "      <td>3.249548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1.354749</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.507194</td>\n",
       "      <td>0.902081</td>\n",
       "      <td>-0.565368</td>\n",
       "      <td>-1.354813</td>\n",
       "      <td>-0.10648</td>\n",
       "      <td>-0.268554</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266146</td>\n",
       "      <td>-0.192901</td>\n",
       "      <td>-0.067116</td>\n",
       "      <td>-0.196006</td>\n",
       "      <td>-0.130783</td>\n",
       "      <td>-0.235849</td>\n",
       "      <td>-0.121613</td>\n",
       "      <td>0.618959</td>\n",
       "      <td>-0.481772</td>\n",
       "      <td>-0.307390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2.506849</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.453112</td>\n",
       "      <td>-1.107304</td>\n",
       "      <td>-0.565368</td>\n",
       "      <td>0.737281</td>\n",
       "      <td>-0.10648</td>\n",
       "      <td>-0.268554</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266146</td>\n",
       "      <td>-0.192901</td>\n",
       "      <td>-0.067116</td>\n",
       "      <td>-0.196006</td>\n",
       "      <td>-0.130783</td>\n",
       "      <td>-0.235849</td>\n",
       "      <td>-0.121613</td>\n",
       "      <td>-1.613803</td>\n",
       "      <td>-0.481772</td>\n",
       "      <td>3.249548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>-0.181385</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.473739</td>\n",
       "      <td>0.902081</td>\n",
       "      <td>-0.565368</td>\n",
       "      <td>0.737281</td>\n",
       "      <td>-0.10648</td>\n",
       "      <td>-0.268554</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266146</td>\n",
       "      <td>-0.192901</td>\n",
       "      <td>-0.067116</td>\n",
       "      <td>-0.196006</td>\n",
       "      <td>-0.130783</td>\n",
       "      <td>-0.235849</td>\n",
       "      <td>-0.121613</td>\n",
       "      <td>0.618959</td>\n",
       "      <td>-0.481772</td>\n",
       "      <td>-0.307390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>-0.565419</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>0.767199</td>\n",
       "      <td>-0.400792</td>\n",
       "      <td>0.902081</td>\n",
       "      <td>-0.565368</td>\n",
       "      <td>-1.354813</td>\n",
       "      <td>-0.10648</td>\n",
       "      <td>-0.268554</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266146</td>\n",
       "      <td>-0.192901</td>\n",
       "      <td>-0.067116</td>\n",
       "      <td>-0.196006</td>\n",
       "      <td>-0.130783</td>\n",
       "      <td>-0.235849</td>\n",
       "      <td>-0.121613</td>\n",
       "      <td>0.618959</td>\n",
       "      <td>-0.481772</td>\n",
       "      <td>-0.307390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId       Age     SibSp     Parch      Fare  Pclass_3  Pclass_1  \\\n",
       "0          892  0.394665 -0.474279 -0.473408 -0.490508  0.902081 -0.565368   \n",
       "1          893  1.354749  0.432550 -0.473408 -0.507194  0.902081 -0.565368   \n",
       "2          894  2.506849 -0.474279 -0.473408 -0.453112 -1.107304 -0.565368   \n",
       "3          895 -0.181385 -0.474279 -0.473408 -0.473739  0.902081 -0.565368   \n",
       "4          896 -0.565419  0.432550  0.767199 -0.400792  0.902081 -0.565368   \n",
       "\n",
       "   Sex_male  TicketPrefix_A/5  TicketPrefix_PC     ...      CabinClass_C  \\\n",
       "0  0.737281          -0.10648        -0.268554     ...         -0.266146   \n",
       "1 -1.354813          -0.10648        -0.268554     ...         -0.266146   \n",
       "2  0.737281          -0.10648        -0.268554     ...         -0.266146   \n",
       "3  0.737281          -0.10648        -0.268554     ...         -0.266146   \n",
       "4 -1.354813          -0.10648        -0.268554     ...         -0.266146   \n",
       "\n",
       "   CabinClass_E  CabinClass_G  CabinClass_D  CabinClass_A  CabinClass_B  \\\n",
       "0     -0.192901     -0.067116     -0.196006     -0.130783     -0.235849   \n",
       "1     -0.192901     -0.067116     -0.196006     -0.130783     -0.235849   \n",
       "2     -0.192901     -0.067116     -0.196006     -0.130783     -0.235849   \n",
       "3     -0.192901     -0.067116     -0.196006     -0.130783     -0.235849   \n",
       "4     -0.192901     -0.067116     -0.196006     -0.130783     -0.235849   \n",
       "\n",
       "   CabinClass_F  Embarked_S  Embarked_C  Embarked_Q  \n",
       "0     -0.121613   -1.613803   -0.481772    3.249548  \n",
       "1     -0.121613    0.618959   -0.481772   -0.307390  \n",
       "2     -0.121613   -1.613803   -0.481772    3.249548  \n",
       "3     -0.121613    0.618959   -0.481772   -0.307390  \n",
       "4     -0.121613    0.618959   -0.481772   -0.307390  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_training.columns[2:]\n",
    "X_train = df_training[columns].values\n",
    "X_test = df_test[columns].values\n",
    "y_train = df_training['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 60)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 60)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = df_test.copy()\n",
    "submission['Survived'] = y_test\n",
    "submission = submission[['PassengerId', 'Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./submissions/'):\n",
    "    os.makedirs('./submissions/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submissions/02_logistic_regression.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My submission to Kaggle produced a 72.72% test prediction accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection - forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating sets for 10-fold cross validation\n",
    "indexes = list(range(len(df_training)))\n",
    "random.shuffle(indexes)\n",
    "folds = []\n",
    "for i in range(10):\n",
    "    folds.append([])\n",
    "for i in range(len(indexes)):\n",
    "    folds[i % 10].append(indexes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_training_test_set(df_training, train_indexes, test_indexes, column_indexes):\n",
    "    columns = df_training.columns[column_indexes]\n",
    "    datasets = {}\n",
    "    datasets['X_train'] = df_training.iloc[train_indexes][columns].values\n",
    "    datasets['X_test'] = df_training.iloc[test_indexes][columns].values\n",
    "    datasets['y_train'] = df_training.iloc[train_indexes]['Survived'].values\n",
    "    datasets['y_test'] = df_training.iloc[test_indexes]['Survived'].values\n",
    "    \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(datasets, C = None):\n",
    "    if C is None:\n",
    "        C = 1\n",
    "    logreg = LogisticRegression(C = C)\n",
    "    logreg.fit(datasets['X_train'], datasets['y_train'])\n",
    "    y_pred = logreg.predict(datasets['X_test'])\n",
    "    return sqrt(np.sum(np.power(np.array(y_pred) - np.array(datasets['y_test']), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(df_training, folds, column_indexes, C = None):\n",
    "    error = 0\n",
    "    \n",
    "    for k in range(10):\n",
    "        train_indexes = []\n",
    "        for j in range(10):\n",
    "            if j == k:\n",
    "                test_indexes = folds[j]\n",
    "            else:\n",
    "                train_indexes = train_indexes + folds[j]\n",
    "                \n",
    "        datasets = produce_training_test_set(df_training, train_indexes, test_indexes, column_indexes)\n",
    "        \n",
    "        error = error + evaluate(datasets, C)\n",
    "        \n",
    "    return error / 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.263014203517338"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_indexes = list(range(2, 62))\n",
    "k_fold_cross_validation(df_training, folds, column_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting feature Sex_male - error decreased to 4.328105960328346\n",
      "Selecting feature TicketPrefix_W./C. - error decreased to 4.281406102952756\n",
      "Selecting feature SibSp - error decreased to 4.23599879067807\n",
      "Selecting feature Pclass_3 - error decreased to 4.153504196089814\n",
      "Selecting feature Age - error decreased to 4.132343766397408\n",
      "Selecting feature CabinClass_E - error decreased to 4.079869492473408\n",
      "Selecting feature TicketPrefix_S.O.C. - error decreased to 4.064489895129577\n",
      "Selecting feature Embarked_Q - error decreased to 4.040744255754691\n",
      "Selecting feature TicketPrefix_SC/Paris - error decreased to 4.028433693192925\n",
      "Selecting feature CabinClass_C - error decreased to 4.017109992047034\n",
      "Selecting feature TicketPrefix_W.E.P. - error decreased to 4.01472312289314\n",
      "Selecting feature CabinClass_F - error decreased to 4.014292192329051\n",
      "Selecting feature TicketPrefix_SW/PP - error decreased to 4.013383246577314\n",
      "Selecting feature TicketPrefix_S.W./PP - error decreased to 4.000681581198056\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "# Forward selection\n",
    "pending = list(range(2, 62))\n",
    "model = []\n",
    "min_error = sys.float_info.max\n",
    "while len(pending) > 0:\n",
    "    \n",
    "    prev_error = min_error\n",
    "    min_error = sys.float_info.max\n",
    "    \n",
    "    for i in pending:\n",
    "        new_model = model + [i]\n",
    "        error = k_fold_cross_validation(df_training, folds, new_model)\n",
    "        \n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            best_model = new_model\n",
    "            feature = i\n",
    "            \n",
    "    if min_error < prev_error:\n",
    "        print('Selecting feature ' + df_training.columns[feature] + ' - error decreased to ' + str(min_error))\n",
    "        model = best_model\n",
    "        pending.remove(feature)\n",
    "    else:\n",
    "        print('END')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forward = model\n",
    "columns = df_training.columns[model_forward]\n",
    "X_train = df_training[columns].values\n",
    "X_test = df_test[columns].values\n",
    "y_train = df_training['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = df_test.copy()\n",
    "submission['Survived'] = y_test\n",
    "submission = submission[['PassengerId', 'Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submissions/02_logistic_regression_forward_selection.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission produced a 75.119% test prediction accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection - bakward elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature TicketPrefix_WE/P - error decreased to 4.238001975576314\n",
      "Removing feature TicketPrefix_SC/AH - error decreased to 4.211783256070852\n",
      "Removing feature TicketPrefix_S.C./PARIS - error decreased to 4.180509295399347\n",
      "Removing feature TicketPrefix_STON/O2. - error decreased to 4.157511815253558\n",
      "Removing feature CabinClass_B - error decreased to 4.143901204122563\n",
      "Removing feature TicketPrefix_CA. - error decreased to 4.132577502976672\n",
      "Removing feature TicketPrefix_A/5 - error decreased to 4.120951677334533\n",
      "Removing feature Pclass_1 - error decreased to 4.110410100985605\n",
      "Removing feature Parch - error decreased to 4.084986728254289\n",
      "Removing feature TicketPrefix_F.C.C. - error decreased to 4.073842100076087\n",
      "Removing feature TicketPrefix_P/PP - error decreased to 4.052175303014539\n",
      "Removing feature TicketPrefix_SOTON/OQ - error decreased to 4.0398647404527726\n",
      "Removing feature TicketPrefix_S.O.C. - error decreased to 4.039817243707889\n",
      "Removing feature TicketPrefix_STON/O - error decreased to 4.002891948849503\n",
      "Removing feature TicketPrefix_F.C. - error decreased to 3.9789555606455975\n",
      "Removing feature TicketPrefix_W.E.P. - error decreased to 3.977297869261966\n",
      "Removing feature TicketPrefix_C.A. - error decreased to 3.9662538952663398\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "# backward elimination\n",
    "model = list(range(2, 62))\n",
    "min_error = k_fold_cross_validation(df_training, folds, column_indexes)\n",
    "while len(model) > 0:\n",
    "    \n",
    "    prev_error = min_error\n",
    "    min_error = sys.float_info.max\n",
    "    \n",
    "    for i in model:\n",
    "        new_model = model[:]\n",
    "        new_model.remove(i)\n",
    "        error = k_fold_cross_validation(df_training, folds, new_model)\n",
    "        \n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            best_model = new_model\n",
    "            feature = i\n",
    "            \n",
    "    if min_error < prev_error:\n",
    "        print('Removing feature ' + df_training.columns[feature] + ' - error decreased to ' + str(min_error))\n",
    "        model = best_model\n",
    "    else:\n",
    "        print('END')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward eliminiation seems to reduce the prediction error for the training set even more. Let's make a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_backward = model\n",
    "columns = df_training.columns[model_backward]\n",
    "X_train = df_training[columns].values\n",
    "X_test = df_test[columns].values\n",
    "y_train = df_training['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = df_test.copy()\n",
    "submission['Survived'] = y_test\n",
    "submission = submission[['PassengerId', 'Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submissions/02_logistic_regression_backward_elimination.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission produced 73.205% prediction accuracy for the test set. Therefore, we should keep forward selection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection - regularisation\n",
    "\n",
    "The only parameter worth playing with is the regularisation factor C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_indexes = model_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.arange(0.01, 1.5, 0.01)\n",
    "rmses = []\n",
    "for c in C:\n",
    "    rmses.append(k_fold_cross_validation(df_training, folds, new_model, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Regularisation factor - model selection')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(C, rmses)\n",
    "ax.set_xlabel('C')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Regularisation factor - model selection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum seems to be at 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_training.columns[model_forward]\n",
    "X_train = df_training[columns].values\n",
    "X_test = df_test[columns].values\n",
    "y_train = df_training['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.7, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = df_test.copy()\n",
    "submission['Survived'] = y_test\n",
    "submission = submission[['PassengerId', 'Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submissions/02_logistic_regression_regularisation.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I obtained exactly the same test accuracy after my submission than in the case of not using regularisation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
