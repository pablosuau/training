{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.read_csv('../../datasets/titanic_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../../datasets/titanic_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we analyse and preprocess the training data to prepare it for machine learning algorithms. We apply exactly the same transformations to the test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PassengerID: row id\n",
    "- Survived: target variable (1 = yes, 0 = no)\n",
    "- Pclass: ticket class\n",
    "- Name: name\n",
    "- Sex: sex\n",
    "- Age: age\n",
    "- SibSp: number of spouses or siblings aboard\n",
    "- Parch: number of parents or children aboard\n",
    "- Ticket: ticket number \n",
    "- Fare: ticket fare\n",
    "- Cabin: assigned cabin number\n",
    "- Embarked: port from which they embarked (C = Cherbourg, Q = Queenstown, S = Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may seem that to make the Ticket and Cabin features we need to transform the data.\n",
    "\n",
    "The Cabin feature is composed of a letter (which correlates to the class) and a number (the specific cabin). It may be interesting to split this feature into two: a categorical feature that may be very correlated to Pclass (CabinClass) and a numerical feature (CabinNumber) that specifies the approximate position from the front to the back of the ship. The problem is that according to Titanic Deck plans there is not a direct relation between the cabin number and distance from the front. It would be useful to use the cabin number to split cabins insto front, middle and back cabins. And also in left and right. However, it is hard to find a good deck plan that indicates the actual positions of the cabins. I will keep cabin number anyway because it may indicate proximity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training['Cabin'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With respect to ticket number, the optional prefix (TicketPrefix) indicates issuing office and the number (TicketNumber) can be compared for equality (sharing a cabin) or for closeness (people with cabins that are close to each other.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_training['Ticket'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't see how to use TicketNumber and CabinNumber as proximity features, so I will stick to TicketPrefix and CabinClass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ticket(df):\n",
    "    df['TicketPrefix'] = df['Ticket']\n",
    "    df.loc[df['Ticket'].notnull(), 'TicketPrefix'] = df['Ticket'].apply(lambda x: x.split(' ')[0] \n",
    "                                                                                  if len(x.split(' ')) > 1\n",
    "                                                                                  else 'NUMBER')\n",
    "    \n",
    "process_ticket(df_training)\n",
    "process_ticket(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training[['Ticket', 'TicketPrefix']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cabin I keep the first letter. There are multiple instances of rows having multiple assigned cabins. In these cases\n",
    "# the first letter is the same for all the assigned cabins, except in two cases in which we have:\n",
    "# F GXX\n",
    "# In this case, for simplicity, I decided to keep the F letter\n",
    "def process_cabin(df):\n",
    "    df['CabinClass'] = df['Cabin']\n",
    "    df.loc[df['Cabin'].notnull(), 'CabinClass'] = df['Cabin'].apply(lambda x: str(x)[0])\n",
    "    \n",
    "process_cabin(df_training)\n",
    "process_cabin(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training[['Cabin', 'CabinClass']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent = 'Survived'\n",
    "categorical = ['Pclass', 'Sex', 'TicketPrefix', 'CabinClass', 'Embarked']\n",
    "numerical = ['Age', 'SibSp', 'Parch', 'Fare']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial exploration\n",
    "\n",
    "We must take into account that there are missing values.\n",
    "\n",
    "Looking at numerical variables first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(histtype = 'stepfilled', alpha = 0.3, density = True, ec = 'k')\n",
    "\n",
    "for n in numerical:\n",
    "    df = df_training[df_training[n].notnull()]\n",
    "    x = df[n].values\n",
    "    y = df[dependent].values\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    (_, bins, _) = ax[0].hist(x, **kwargs)\n",
    "    ax[0].set_title(n)\n",
    "    \n",
    "    x_0 = x[np.where(y == 0)]\n",
    "    x_1 = x[np.where(y == 1)]\n",
    "    ax[1].hist(x_0, **kwargs, bins = bins)\n",
    "    ax[1].hist(x_1, **kwargs, bins = bins)\n",
    "    ax[1].legend(['no', 'yes'])\n",
    "    ax[1].set_title(n + ' vs. survived')\n",
    "    \n",
    "    fig.set_figwidth(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that all the numerical features may provide useful information in predicting the dependent variable:\n",
    "\n",
    "* Younger passengers are more likely to survive\n",
    "* Passengers with not too few or too many embarked siblings/spouses are more likely to survive\n",
    "* Passengers are more likely to survive if they embarked with parents/children\n",
    "* Cheaper fares are less likely to survive.\n",
    "\n",
    "Let's take a look at the categorical features now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in categorical:\n",
    "    df = df_training[df_training[c].notnull()]\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    freqs = df[c].value_counts()\n",
    "    labels = freqs.keys()\n",
    "    ax[0].bar(range(len(labels)), freqs.values, alpha = 0.3)\n",
    "    ax[0].set_xticks(range(len(labels)))\n",
    "    ax[0].set_xticklabels(labels, rotation = 'vertical')\n",
    "    ax[0].set_title(c)\n",
    "    \n",
    "    freqs_01 = df.groupby('Survived')[c].value_counts()\n",
    "    ax[1].bar(range(len(labels)), freqs_01[0][labels].values, alpha = 0.3)\n",
    "    ax[1].bar(range(len(labels)), freqs_01[1][labels].values, bottom = freqs_01[0][labels].values, alpha = 0.3)\n",
    "    ax[1].set_xticks(range(len(labels)))\n",
    "    ax[1].set_xticklabels(labels, rotation = 'vertical')\n",
    "    ax[1].legend(['no', 'yes'])\n",
    "    ax[1].set_title(c + ' vs. survived')\n",
    "    \n",
    "    fig.set_figwidth(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the categorical features seem to also provide information about survival likelihood. For instance, it is more likely to survive if you are a woman, or if your cabin prefix is not T. Many of the passengers with ticket class = 1 did not survived. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing values\n",
    "\n",
    "Let's take a look at the proportion of missing data. Some of the fare values are zero, but we decided not to assume that this is bogus data. I am assumming that these 17 passengers travelled with a zero fare for an explainable reason. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_missing():\n",
    "    for col in numerical + categorical:\n",
    "        if col in categorical:\n",
    "            missing = df_training[df_training[col].isna()]\n",
    "        else:\n",
    "            missing = df_training[(df_training[col].isna()) | \n",
    "                                  (df_training[col].apply(lambda x: type(x) == str))]\n",
    "        proportion = len(missing) / len(df_training) * 100\n",
    "        print(col + ': ' + str(proportion) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_missing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two categorical variables (CabinClass and Embarked) and one numerica variable (age) with missing values. I am going to assign a new value 'Missing' to the case of the missing values for the categorical variables. For the imputation of the numerical variable I am going to go for something simple and just use the median imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables\n",
    "for c in ['CabinClass', 'Embarked']:\n",
    "    df_training.loc[df_training[c].isna(), c] = 'None'\n",
    "    df_test.loc[df_training[c].isna(), c] = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical variable\n",
    "imputed = df_training[np.isreal(df_training['Age'])]['Age'].median()\n",
    "df_training[(df_training['Age'].isna()) | (~np.isreal(df_training['Age']))]['Age'] = imputed\n",
    "df_test[(df_test['Age'].isna()) | (~np.isreal(df_test['Age']))]['Age'] = imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_missing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between variables\n",
    "\n",
    "We calculate pearson correlation in order to determine whether we should remove any variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = categorical + numerical\n",
    "\n",
    "fig, ax = plt.subplots(6, 6)\n",
    "\n",
    "plots = 0\n",
    "for i in range(len(features)):\n",
    "    for j in range(i + 1, len(features)):\n",
    "        row = int(plots / 6)\n",
    "        col = plots % 6\n",
    "\n",
    "        def categorical_to_numerical(f):\n",
    "            if features[f] in numerical:\n",
    "                values_f = df_training[features[f]]\n",
    "            else:\n",
    "                values = df_training[features[f]].unique()\n",
    "                values_f = df_training[features[f]].values.copy()\n",
    "                for v in range(len(values)):\n",
    "                    values_f[np.where(values_f == values[v])] = v\n",
    "            \n",
    "            return values_f\n",
    "        \n",
    "        values_i = categorical_to_numerical(i)\n",
    "        values_j = categorical_to_numerical(j)\n",
    "        \n",
    "        cor = ((values_i - values_i.mean()) * (values_j - values_j.mean()) / \\\n",
    "              ((len(values_i) - 1) * values_i.std() * values_j.std())).sum()\n",
    "            \n",
    "        ax[row][col].scatter(values_i, values_j, alpha = 0.5)\n",
    "        \n",
    "        ax[row][col].set_xlabel(features[i])\n",
    "        ax[row][col].set_ylabel(features[j])\n",
    "        ax[row][col].set_title('cor = ' + '%.2f' % cor)\n",
    "        \n",
    "        if features[i] in categorical:\n",
    "            values = df_training[features[i]].unique().tolist()\n",
    "            ax[row][col].set_xticks(range(len(values)))\n",
    "            ax[row][col].set_xticklabels(values, rotation = 'vertical')\n",
    "        if features[j] in categorical:\n",
    "            values = df_training[features[j]].unique().tolist()\n",
    "            ax[row][col].set_yticks(range(len(values)))\n",
    "            ax[row][col].set_yticklabels(values)\n",
    "\n",
    "        plots = plots + 1\n",
    "        \n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't observe any strong correlation. I cannot observe any obvious outlier either. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy variables\n",
    "\n",
    "Transforming categorical variables into dummy variables (we create k-1 new binary variables for each categorical variable, where k is the number of values of that categorical variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_categorical = []\n",
    "for c in categorical:\n",
    "    values = df_training[c].unique()[:-1]\n",
    "    for v in values:\n",
    "        name = c + '_' + str(v)\n",
    "        df_training[name] = (df_training[c] == v).astype(int)\n",
    "        df_test[name] = (df_test[c] == v).astype(int)\n",
    "        new_categorical.append(name)\n",
    "    df_training = df_training.drop(c, axis = 1)\n",
    "    df_test = df_test.drop(c, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(categorical + numerical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = new_categorical + numerical\n",
    "print(len(variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this step our training dataset contains 60 variables instead of 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardise\n",
    "\n",
    "We want to keep the correlation between variables. Therefore, we use standardisation instead of normalisation. This step is not necessary for some machine learning algorithms, but can help others to converge much faster and also to prevent bias in those machine learning algorithms based on the Euclidean distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping this values to transform the test dataset\n",
    "statistics = pd.concat((df_training.mean(), df_training.std()), axis = 1)\n",
    "statistics.columns = ['mean', 'std']\n",
    "statistics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in variables:\n",
    "    mean = statistics.loc[c, 'mean']\n",
    "    std = statistics.loc[c, 'std']\n",
    "    df_training[c] = (df_training[c] - mean) /  std\n",
    "    df_test[c] = (df_test[c] - mean) /  std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training[variables].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class imbalance\n",
    "\n",
    "Finally we test whether the training set has a class imbalance problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str((df_training.Survived == 1).sum()) + ' rows have Survived = 1')\n",
    "print(str((df_training.Survived == 0).sum()) + ' rows have Survived = 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's some imbalance in the data, but does not seem to extreme. I decided not to oversample the minority class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
