{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import itertools\n",
    "import inspect\n",
    "import multiprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from math import sqrt\n",
    "from  warnings import simplefilter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "simplefilter('ignore', category = ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.read_csv('../../datasets/titanic_training_processed.csv')\n",
    "df_test = pd.read_csv('../../datasets/titanic_test_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_training.columns[2:]\n",
    "X_train = df_training[columns].values\n",
    "X_test = df_test[columns].values\n",
    "y_train = df_training['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No feature selection\n",
    "\n",
    "We have to still apply 10-fold cross validation to select the kernel and the value of C. For the polynomial and RBF kernels we also need to determine the value of their respective parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating sets for 10-fold cross validation\n",
    "indexes = list(range(len(df_training)))\n",
    "random.shuffle(indexes)\n",
    "folds = []\n",
    "for i in range(10):\n",
    "    folds.append([])\n",
    "for i in range(len(indexes)):\n",
    "    folds[i % 10].append(indexes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_training_test_set(df_training, train_indexes, test_indexes, column_indexes):\n",
    "    columns = df_training.columns[column_indexes]\n",
    "    datasets = {}\n",
    "    datasets['X_train'] = df_training.iloc[train_indexes][columns].values\n",
    "    datasets['X_test'] = df_training.iloc[test_indexes][columns].values\n",
    "    datasets['y_train'] = df_training.iloc[train_indexes]['Survived'].values\n",
    "    datasets['y_test'] = df_training.iloc[test_indexes]['Survived'].values\n",
    "    \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(datasets, C, kernel, kernel_params):\n",
    "    kwargs = {}\n",
    "    if kernel == 'poly':\n",
    "        kwargs['degree'] = kernel_params['degree']\n",
    "        kwargs['coef0'] = kernel_params['coef0']\n",
    "       \n",
    "    clf = SVC(max_iter = 50000, C = C, gamma = 'auto', kernel = kernel, **kwargs)\n",
    "    clf.fit(datasets['X_train'], datasets['y_train'])\n",
    "    y_pred = clf.predict(datasets['X_test'])\n",
    "    return sqrt(np.sum(np.power(np.array(y_pred) - np.array(datasets['y_test']), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(df_training, folds, column_indexes, C, kernel, kernel_params):\n",
    "    error = 0\n",
    "    \n",
    "    for k in range(10):\n",
    "        train_indexes = []\n",
    "        for j in range(10):\n",
    "            if j == k:\n",
    "                test_indexes = folds[j]\n",
    "            else:\n",
    "                train_indexes = train_indexes + folds[j]\n",
    "                \n",
    "        datasets = produce_training_test_set(df_training, train_indexes, test_indexes, column_indexes)\n",
    "        \n",
    "        error = error + evaluate(datasets, C, kernel, kernel_params)\n",
    "        \n",
    "    return error / 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results were very similar for gamma = scale and gamma = auto\n",
    "# No good results with degree = 1\n",
    "# Manually setting the ranges and steps after testing multiple times so we do not get so many combinations\n",
    "# for the feature selection case\n",
    "C = np.arange(0.2, 5.2, 0.2).tolist()\n",
    "kernel = ['linear', 'poly', 'rbf']\n",
    "degree = [2, 3]\n",
    "coef0 = np.arange(0, 3.2, 0.2).tolist()\n",
    "\n",
    "poly_params = list(itertools.product(*[degree, coef0]))\n",
    "\n",
    "comb = list(itertools.product(*[C, ['linear'], [None], [None]]))\n",
    "comb.extend(list(itertools.product(*[C, ['rbf'], [None], [None]])))\n",
    "comb.extend(list(itertools.product(*[C, ['poly'], degree, coef0])))\n",
    "\n",
    "column_indexes = list(range(2, 62)) # All columns\n",
    "minimum = sys.float_info.max\n",
    "\n",
    "errors = pd.DataFrame(data = comb, columns = ['C', 'kernel', 'degree', 'coef0'])\n",
    "errors['error'] = np.nan\n",
    "\n",
    "for i in tqdm(range(len(errors))):\n",
    "    errors.loc[i, 'error'] = k_fold_cross_validation(df_training,\n",
    "                                                     folds,\n",
    "                                                     column_indexes,\n",
    "                                                     errors['C'].loc[i],\n",
    "                                                     errors['kernel'].loc[i],\n",
    "                                                     {'degree': errors['degree'].loc[i],\n",
    "                                                      'coef0': errors['coef0'].loc[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = errors.sort_values(by = 'error')\n",
    "errors.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "errors_linear = errors[errors.kernel == 'linear'].sort_values(by = 'C')\n",
    "ax.plot(errors_linear.C, errors_linear.error)\n",
    "ax.set_xlabel('C')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Linear model')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "errors_rbf = errors[errors.kernel == 'rbf'].sort_values(by = 'C')\n",
    "ax.plot(errors_rbf.C, errors_rbf.error)\n",
    "ax.set_xlabel('C')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('RBF kernel')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, len(degree))\n",
    "errors_poly = errors[errors.kernel == 'poly']\n",
    "for d in degree:\n",
    "    i = degree.index(d)\n",
    "    errors_d = errors_poly[errors_poly.degree == d].pivot(index='C', \n",
    "                                                          columns='coef0', \n",
    "                                                          values='error')\n",
    "    im = ax[i].imshow(errors_d, cmap = 'viridis', extent=[errors.C.min(), \n",
    "                                                          errors.C.max(), \n",
    "                                                          errors.coef0.min(), \n",
    "                                                          errors.coef0.max()])\n",
    "    fig.colorbar(im, ax = ax[i])\n",
    "    ax[i].set_xlabel('C')\n",
    "    ax[i].set_ylabel('coef0')\n",
    "    ax[i].set_title('poly kernel - degree = ' + str(d))\n",
    "fig.set_figwidth(12)\n",
    "fig.set_figheight(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_C = errors.C.values[0]\n",
    "best_kernel = errors.kernel.values[0]\n",
    "best_degree = errors.degree.values[0]\n",
    "best_coef0 = errors.coef0.values[0]\n",
    "clf = SVC(C = best_C, \n",
    "          gamma = 'auto', \n",
    "          kernel = best_kernel, \n",
    "          degree = best_degree,\n",
    "          coef0 = best_coef0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = df_test.copy()\n",
    "submission['Survived'] = y_test\n",
    "submission = submission[['PassengerId', 'Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./submissions/'):\n",
    "    os.makedirs('./submissions/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submissions/05_svm.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My submission to Kaggle produced a 78.95% test prediction accuracy. This is almost as high as what I my best result *with feature selection* to this date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection - forward selection\n",
    "\n",
    "Unfortunately I cannot apply full model selection during feature selection. I will use the best model parameter values obtained by applying model selection to the full mmodel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation_unpack(args):\n",
    "    from tmp_func import k_fold_cross_validation\n",
    "    \n",
    "    return k_fold_cross_validation(args[0],\n",
    "                                   args[1],\n",
    "                                   args[2],\n",
    "                                   args[3][0],\n",
    "                                   args[3][1],\n",
    "                                   {'degree': args[3][2], 'coef0': args[3][3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp_func.py', 'w') as f:\n",
    "    f.write('from math import sqrt\\n')\n",
    "    f.write('from sklearn.svm import SVC\\n')\n",
    "    f.write('import numpy as np\\n')\n",
    "    f.write(inspect.getsource(evaluate))\n",
    "    f.write(inspect.getsource(produce_training_test_set))\n",
    "    f.write(inspect.getsource(k_fold_cross_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Forward selection\n",
    "pending = list(range(2, 62))\n",
    "model = []\n",
    "min_error = sys.float_info.max\n",
    "num_processes = multiprocess.cpu_count() - 1\n",
    "\n",
    "while len(pending) > 0:\n",
    "    prev_error = min_error\n",
    "    \n",
    "    for i in tqdm(pending):\n",
    "        new_model = model + [i]\n",
    "        parameters = itertools.product([df_training], [folds], [new_model], comb)\n",
    "        with multiprocess.Pool(processes = num_processes) as pool:\n",
    "            errors = pool.map(k_fold_cross_validation_unpack, parameters)\n",
    "       \n",
    "        minimum = min(errors) \n",
    "        if minimum < min_error:\n",
    "            min_error = minimum\n",
    "            best_model = new_model\n",
    "            feature = i\n",
    "            best_comb = comb[np.argmin(errors)]\n",
    "        \n",
    "    if min_error < prev_error:\n",
    "        print('Selecting feature ' + \n",
    "              df_training.columns[feature] + \n",
    "              '(C = ' + \n",
    "              str(best_comb[0]) +\n",
    "              ', kernel = ' +\n",
    "              best_comb[1] +\n",
    "              ', degree = ' + \n",
    "              str(best_comb[2]) +\n",
    "              ', coef0 = ' +\n",
    "              str(best_comb[3]) + \n",
    "              ') - error decreased to ' +\n",
    "              str(min_error))\n",
    "        model = model + [feature]\n",
    "        pending.remove(feature)\n",
    "    else:\n",
    "        print('END')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forward = model\n",
    "columns = df_training.columns[model_forward]\n",
    "X_train = df_training[columns].values\n",
    "X_test = df_test[columns].values\n",
    "y_train = df_training['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict()\n",
    "if best_comb[1] == 'poly':\n",
    "    kwargs['degree'] = best_comb[2]['degree']\n",
    "    kwargs['coef0'] = best_comb[3]['coef0']\n",
    "       \n",
    "clf = SVC(C = best_comb[0], gamma = 'auto', kernel = best_comb[1], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = df_test.copy()\n",
    "submission['Survived'] = y_test\n",
    "submission = submission[['PassengerId', 'Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submissions/05_svm_forward_selection.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we got a lower error with this subset of features as compared as to the whole set (RMSE = 3.77 vs RMSE = 3.9), this submissions only got a 76.55% accuracy on Kaggle vs. the 78.95% I got with the complete set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection - backward elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward elimination\n",
    "model = list(range(2, 62))\n",
    "# Using the results for the full model's best model\n",
    "min_error = k_fold_cross_validation(df_training, \n",
    "                                    folds, \n",
    "                                    column_indexes, \n",
    "                                    best_C, \n",
    "                                    best_kernel, \n",
    "                                    {'degree': best_degree, \n",
    "                                     'coef0': best_coef0})\n",
    "num_processes = multiprocess.cpu_count() - 1\n",
    "\n",
    "while len(model) > 0:\n",
    "    prev_error = min_error\n",
    "    \n",
    "    for i in tqdm(model):\n",
    "        new_model = model[:]\n",
    "        new_model.remove(i)\n",
    "        parameters = itertools.product([df_training], [folds], [new_model], comb)\n",
    "        \n",
    "        with multiprocess.Pool(processes = num_processes) as pool:\n",
    "            errors = pool.map(k_fold_cross_validation_unpack, parameters)\n",
    "        \n",
    "        minimum = min(errors)\n",
    "        \n",
    "        if minimum < min_error:\n",
    "            min_error = minimum\n",
    "            best_model = new_model\n",
    "            feature = i\n",
    "            best_comb = comb[np.argmin(errors)]\n",
    "            \n",
    "    if min_error < prev_error:\n",
    "        print('Removing feature ' + \n",
    "              df_training.columns[feature] + \n",
    "              '(C = ' + \n",
    "              str(best_comb[0]) +\n",
    "              ', kernel = ' +\n",
    "              best_comb[1] +\n",
    "              ', degree = ' + \n",
    "              str(best_comb[2]) +\n",
    "              ', coef0 = ' +\n",
    "              str(best_comb[3]) + \n",
    "              ') - error decreased to ' +\n",
    "              str(min_error))\n",
    "        model = best_model\n",
    "    else:\n",
    "        print('END')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_backward = model\n",
    "columns = df_training.columns[model_backward]\n",
    "X_train = df_training[columns].values\n",
    "X_test = df_test[columns].values\n",
    "y_train = df_training['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict()\n",
    "if best_comb[1] == 'poly':\n",
    "    kwargs['degree'] = best_comb[2]\n",
    "    kwargs['coef0'] = best_comb[3]\n",
    "       \n",
    "clf = SVC(C = best_comb[0], gamma = 'auto', kernel = best_comb[1], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = df_test.copy()\n",
    "submission['Survived'] = y_test\n",
    "submission = submission[['PassengerId', 'Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submissions/05_svm_backward_elimination.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission produced the same accuracy as the complete model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('./tmp_func.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
