{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to demonstrate the effect that different types of outliers can have on the slope of the fitted linear model. We can distinguish three types of outliers:\n",
    "\n",
    "- A high leverage point is an observation that is horizontally distant with respect to the rest of observations. A high leverage point may or may not have a big impact on the slope of the fitted linear model.\n",
    "- An influential point is a leverage point that has a big impact on the slope of the linear model\n",
    "- Finally, we can have outliers that are neigher high leverage nor influential points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SIZE = 100\n",
    "def generate_random_linear_sample(slope, intercept, noise_std, x_init, x_end):\n",
    "    x = np.random.uniform(x_init, x_end, SIZE)\n",
    "    y = x*slope + intercept + np.random.normal(0, noise_std, SIZE)\n",
    "    \n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SLOPE = -1.23\n",
    "INTERCEPT = 5\n",
    "NOISE_STD = 5\n",
    "x, y = generate_random_linear_sample(SLOPE, INTERCEPT, NOISE_STD, 20, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 1/(len(x) - 1)*np.sum((x - np.mean(x))*(y - np.mean(y))/(np.std(x) * np.std(y)))\n",
    "b1 = R * np.std(y) / np.std(x)\n",
    "b0 = np.mean(y) - b1 * np.mean(x)\n",
    "\n",
    "def predict(x, b0, b1):\n",
    "    return(b0 + b1*x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "ax.plot([np.min(x), np.max(x)], [predict(np.min(x), b0, b1), predict(np.max(x), b0, b1)], 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High leverage (non-influential point)\n",
    "\n",
    "This kind of outlier does not have a big impact on the slope of the fitted linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_c = copy.deepcopy(x)\n",
    "y_c = copy.deepcopy(y)\n",
    "\n",
    "x_c = np.append(x_c, 100)\n",
    "y_c = np.append(y_c, 100*SLOPE + INTERCEPT + np.random.normal(0, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 1/(len(x_c) - 1)*np.sum((x_c - np.mean(x_c))*(y_c - np.mean(y_c))/(np.std(x_c) * np.std(y_c)))\n",
    "b1 = R * np.std(y_c) / np.std(x_c)\n",
    "b0 = np.mean(y_c) - b1 * np.mean(x_c)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x_c, y_c)\n",
    "ax.plot([np.min(x_c), np.max(x_c)], [predict(np.min(x_c), b0, b1), predict(np.max(x_c), b0, b1)], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
