{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: on this notebook I am just practicing concepts of multiple linear regression. I am not considering some aspects related to machine learning like the imputation of missing values or the normalisation of the predictor variables. \n",
    "\n",
    "The dataset used in this notebook is the Auto MPG dataset from the UCI Machine Learning Repository: (https://archive.ics.uci.edu/ml/datasets/Auto+MPG).\n",
    "\n",
    "The mpg column corresponds to the response variable. All the predictor variables can be interpreted as numerical variables except origin, that is categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/auto-mpg.csv', sep='\\s+', header=None, usecols=range(8))\n",
    "df.columns = ['mpg', 'cylinders', 'displacement',\n",
    "              'horsepower', 'weight', 'acceleration',\n",
    "              'model_year', 'origin']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing rows with missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df.horsepower == '?')]\n",
    "df.horsepower = df.horsepower.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,4)\n",
    "\n",
    "ax[0,0].hist(df.mpg)\n",
    "ax[0,0].set_title('mpg distribution')\n",
    "\n",
    "ax[0,1].hist(df.cylinders)\n",
    "ax[0,1].set_title('cylinders distribution')\n",
    "\n",
    "ax[0,2].hist(df.displacement)\n",
    "ax[0,2].set_title('displacement distribution')\n",
    "\n",
    "ax[0,3].hist(df.horsepower)\n",
    "ax[0,3].set_title('horsepower distribution')\n",
    "\n",
    "ax[1,0].hist(df.weight)\n",
    "ax[1,0].set_title('weight distribution')\n",
    "\n",
    "ax[1,1].hist(df.acceleration)\n",
    "ax[1,1].set_title('acceleration distribution')\n",
    "\n",
    "ax[1,2].hist(df.model_year)\n",
    "ax[1,2].set_title('model_year distribution')\n",
    "\n",
    "ax[1,3].hist(df.origin)\n",
    "ax[1,3].set_title('origin distribution')\n",
    "\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(4)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are testing now whether any pair of predictors are collinear, that is, whether any pair of predictors is correlated. Collinearity is an issue since small variations in the data or the model may produce large erratic changes in the point estimates of the multiple regression model. This does not affect the accuracy of the prediction as a whole, but may have an impact on the accuracy of the prediction of each individual predictor.\n",
    "\n",
    "There are 7 predictor variables, making a total of 7*6/2 = 21 combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5,5)\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "for i in range(1,len(df.columns)):\n",
    "    for j in range(i+1,len(df.columns)):\n",
    "        \n",
    "        var1 = df[df.columns[i]]\n",
    "        var2 = df[df.columns[j]]\n",
    "        \n",
    "        ax[row, col].scatter(var1, var2)\n",
    "        \n",
    "        R = 1/(len(df)-1)*np.sum(((var1-var1.mean())/var1.std())*((var2-var2.mean())/var2.std()))\n",
    "        \n",
    "        ax[row, col].set_title(df.columns[i] + ' vs ' + df.columns[j] + '\\nR = ' + str(R))\n",
    "        \n",
    "        col = col + 1\n",
    "        if col > 4:\n",
    "            col = 0\n",
    "            row = row + 1\n",
    "            \n",
    "fig.set_figwidth(14)\n",
    "fig.set_figheight(14)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a somehow strong linear relationship between a set of four variables: displacement, horsepower, weight and cylinders. We will examine later, during model selection, how this may affect the accuracy of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use categorical predictor variables in our multiple regression model (in our case only the 'origin' predictor is categorical) we need to transform them into indicator or dummy variables. An indicator variable takes the value 1 or 0 depending on whether the value represented by the indicator variable was the value of the original categorical variable in the original dataset. If the categorical variable only has two levels only one indicator variable is required. Otherwise, we will need to create one indicator variable for each value of the categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(df.origin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in np.unique(df.origin):\n",
    "    df['origin_' + str(v)] = (df.origin == v).astype(int)\n",
    "del df['origin']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use least squares to fit the multiple regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['cylinders', 'displacement', 'horsepower', 'weight',\n",
    "        'acceleration', 'model_year', 'origin_1', 'origin_2', 'origin_3']\n",
    "\n",
    "Y = df.mpg.values\n",
    "X = df[columns].values\n",
    "\n",
    "X = np.append(np.ones((X.shape[0], 1)), X, axis=1)\n",
    "\n",
    "B = np.dot(np.dot(np.linalg.inv(np.dot(X.T, X)), X.T), Y)\n",
    "\n",
    "print('Fitted linear model:')\n",
    "print('intercept: ' + str(B[0]))\n",
    "for i in range(len(columns)):\n",
    "    print(columns[i] + ': ' + str(B[i-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: plot linear regression for each predictor variable to test that it worked"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
