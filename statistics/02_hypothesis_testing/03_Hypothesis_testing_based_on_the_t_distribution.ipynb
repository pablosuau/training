{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.misc import factorial\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-sample t-test\n",
    "\n",
    "In this example we show an interactive demo of how to perform a hypothesis test of the population mean based on the t-distribution. We use the t-distribution to test the population mean when the sampling distribution of the point estimate of interest (in this case the sample mean) is nearly normally distributed and the sample is small.\n",
    "\n",
    "The thicker tails of the t-distribution, compared to those of the normal distribution, is the correction factor we need to compensate for the small size of the sample. \n",
    "\n",
    "We follow the same process followed for the case of hypothesis testing based on the normal model, but using the t-distribution instead. The T-score is the equivalent of the Z-score in this context, and it is calculated exactly in the same way. \n",
    "\n",
    "The one-sample t-test is commonly applied to large samples as well because the results are then very similar to those of hypothesis testing based on the normal model. This is because the t-distribution becomes practically indistinguishible from the normal distribution when the value of the degrees of freedom is higher than 30. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_one, ax_one = plt.subplots()\n",
    "ax_one.grid(True)\n",
    "plt.ion()\n",
    "\n",
    "POINTS_ONE = 1000\n",
    "\n",
    "def my_label(text, width='20%'):\n",
    "    return widgets.Label(text, layout=widgets.Layout(width=width))  \n",
    "\n",
    "pm_one = widgets.FloatText(value=0)\n",
    "sm_one = widgets.FloatText(value=0.1)\n",
    "ssd_one = widgets.FloatText(value=1)\n",
    "ss_one = widgets.FloatText(value=10, min=3)\n",
    "sl_one = widgets.FloatText(value=0.05, min=0.01, max=0.99)\n",
    "osts_one = widgets.RadioButtons(options=['One-sided (left)', 'One-sided (right)', 'Two-sided'])\n",
    "result1_one = my_label('', width='100%') \n",
    "result2_one = my_label('', width='100%') \n",
    "\n",
    "box_one = widgets.VBox([\n",
    "    my_label('Population'),\n",
    "    widgets.HBox([my_label('Mean (null hypothesis)'), pm_one]),\n",
    "    my_label('Sample'),\n",
    "    widgets.HBox([my_label('Mean'), sm_one]),\n",
    "    widgets.HBox([my_label('Standard deviation'), ssd_one]),\n",
    "    widgets.HBox([my_label('Size'), ss_one]),\n",
    "    my_label('Hypothesis test'), \n",
    "    widgets.HBox([my_label('Significance level'), sl_one]),\n",
    "    osts_one,\n",
    "    result1_one,\n",
    "    result2_one\n",
    "])\n",
    "\n",
    "# Plots the t-distribution distribution centered around the null hypothesis and with\n",
    "# standard deviation = standard error of the sampling distribution. The area of the curve \n",
    "# corresponding to the alternate hypothesis is highlighted\n",
    "def on_change_one(change):\n",
    "    global fig_one, ax_one\n",
    "    \n",
    "    # Auxiliar functions\n",
    "    def compute_pdf(x, mean, std, df):\n",
    "        def gamma(n):\n",
    "            return factorial(n-1)\n",
    "        return gamma((df+1)/2)/(math.sqrt(math.pi*df)*std_one*gamma(df/2))*(1 + ((x-mean_one)/std_one)**2/df)**-((df+1)/2)\n",
    "    \n",
    "    def plot_alternate_hypothesis(start, end, mean, std, df, ax):\n",
    "        if start == 0 and end == 0:\n",
    "            x = np.array([0])\n",
    "        else:\n",
    "            x = np.arange(start, end, (end - start)/POINTS_ONE)\n",
    "        y = compute_pdf(x, mean, std, df)\n",
    "        ax.fill_between(x, 0, y, color='red', alpha=0.3)\n",
    "    \n",
    "    # Deleting previous figure\n",
    "    while len(ax_one.lines) > 0:\n",
    "        l = ax_one.lines.pop(0)\n",
    "        del l\n",
    "    while len(ax_one.collections) > 0:\n",
    "        c = ax_one.collections.pop(0)\n",
    "        del c\n",
    "        \n",
    "    # Plotting - The null hypothesis is distributed following a t-distribution which mean is the \n",
    "    # assumed population mean, standard deviation is the standard error of the sample, and\n",
    "    # degrees of freedom is equal to the number of observations in the sample minus one\n",
    "    mean_one = pm_one.value\n",
    "    std_one = ssd_one.value / math.sqrt(ss_one.value)\n",
    "    df_one = ss_one.value - 1\n",
    "    x_one = np.arange(mean_one-3*std_one, mean_one+3*std_one, 6*std_one/POINTS_ONE)\n",
    "    y_one = compute_pdf(x_one, mean_one, std_one, df_one)\n",
    "    ax_one.plot(x_one,y_one,color='blue')\n",
    "    ax_one.set_xlim([mean_one-3*std_one, mean_one+3*std_one])\n",
    "    \n",
    "    # Plotting - red vertical line for the alternate hypothesis\n",
    "    if osts_one.value == 'One-sided (left)':\n",
    "        plot_alternate_hypothesis(-3*std_one, sm_one.value, mean_one, std_one, df_one, ax_one)\n",
    "        p_value_one = scipy.stats.t(loc=mean_one, scale=std_one, df=df_one).cdf(sm_one.value)\n",
    "    elif osts_one.value == 'One-sided (right)':\n",
    "        plot_alternate_hypothesis(sm_one.value, 3*std_one, mean_one, std_one, df_one, ax_one)\n",
    "        p_value_one = 1 - scipy.stats.t(loc=mean_one, scale=std_one, df=df_one).cdf(sm_one.value)\n",
    "    else:\n",
    "        if sm_one.value >= pm_one.value:\n",
    "            plot_alternate_hypothesis(-3*std_one, -sm_one.value, mean_one, std_one, df_one, ax_one)\n",
    "            plot_alternate_hypothesis(sm_one.value, 3*std_one, mean_one, std_one, df_one, ax_one)\n",
    "            p_value_one = 2*scipy.stats.t(loc=mean_one, scale=std_one, df=df_one).cdf(-sm_one.value)\n",
    "        elif sm_one.value < pm_one.value:\n",
    "            plot_alternate_hypothesis(-3*std_one, sm_one.value, mean_one, std_one, df_one, ax_one)\n",
    "            plot_alternate_hypothesis(-sm_one.value, 3*std_one, mean_one, std_one, df_one, ax_one)\n",
    "            p_value_one = 2*scipy.stats.t(loc=mean_one, scale=std_one, df=df_one).cdf(sm_one.value)\n",
    "            \n",
    "    # Result of the hypothesis test\n",
    "    result1_one.value = 'Result of the test: p-value = ' + str(p_value_one)\n",
    "    if p_value_one < sl_one.value:\n",
    "        result2_one.value = 'We reject the null hypothesis'\n",
    "    else:\n",
    "        result2_one.value = 'We fail to reject the null hypothesis'\n",
    "        \n",
    "    fig_one.canvas.draw()\n",
    "    \n",
    "wid_one = [pm_one, sm_one, ssd_one, ss_one, sl_one, osts_one]\n",
    "[w.observe(on_change_one) for w in wid_one]\n",
    "on_change_one(None)\n",
    "\n",
    "display(box_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-sample t-test (paired data)\n",
    "\n",
    "We say that we have paired data when we work with two datasets in which one observation from one dataset corresponds to exactly another single observation from the second dataset. To test whether there is a difference between the mean of the two populations we create a derived dataset by substracting each observation from the first sample to the corresponding observation from the second sample, and we perform a one-sample t-test in which the null hypothesis is that the mean of the derived dataset is equal to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-sample t-test\n",
    "\n",
    "The two-sample t-test is aimed at determining whether there is a difference between the mean of two populations when data is not paired. The point estimate is calculated from a sample from each population by substracting their sample means. It is aimed at extracting conclusions from experiments: \"is there a difference between the treatment and the control groups?\". In this setting, the null hypothesis considers that the value of the difference of means is zero. \n",
    "\n",
    "In this example we will assume that we have some evidence that the standard deviation of the two populations is approximately the same. That's the reason why the demo only lets you set the value of the standard deviation of one of the samples and then creates a random very similar standard deviation value for the second sample. \n",
    "\n",
    "Given this assumption we can use the pooled variance method to improve the estimation of the standard deviation of the sampling distributions. The pooled variance method also lets us assign a higher value to the degrees of freedom parameter of the t-distribution, therefore letting us apply the test on a t-distribution that looks closer to a normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
