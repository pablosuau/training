{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power calculation and effect size\n",
    "\n",
    "The aim of power calculation is to determine what should be the size of the sample in a experiment so that it will be very likely to dettect a target difference between the treatment and the control group if that difference actually exists. That target difference between the treatment and control populations is the effect size. A power of 80%-90% is a good trade-off between a high likelihood of detecting the effect size in the experiment and not having to expose too many subjects to an experimental treatment.\n",
    "\n",
    "In this first example, we demonstrate how to compute the power of an experiment given a target effect size, a sample size and a significance level. Let's first define the problem. Let's assume that we are conducting an experiment in which we are trying to determine whether not using electronic devices in bed just before sleeping increases the quality of sleep of teenagers. We do this by measuring the hours of deep sleep in two groups of subjects: a treatment group in which subjects do not use any electronic device in bed and a control group that spends half an hour in bed using their phones for messaging, browsing the internet, etc. The subjects are randomly chosen from the population of teenagers in a given area and randomly assigned to groups.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mean, standard deviation and number of observations in the first sample\n",
    "MEAN_TREATMENT = 3.7\n",
    "STD_TREATMENT = 1.3\n",
    "N_TREATMENT = 20\n",
    "# Mean, standard deviation and number of observations in the second sample\n",
    "MEAN_CONTROL = 3.1\n",
    "STD_CONTROL = 1.7\n",
    "N_CONTROL = 20\n",
    "# Significance level\n",
    "SL = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Null hypothesis: the difference between the treatment and the control group is zero hours\n",
    "- Alternate hypothesis: the difference between the treatment and the control group is one hour\n",
    "\n",
    "This one hour is the effect size of interest for which we are aiming at having a large likelihood of detecting, if such difference really exists between the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the standard error for a two-sample t test\n",
    "se = math.sqrt(STD_TREATMENT**2/N_TREATMENT + STD_CONTROL**2/N_CONTROL)\n",
    "print(se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the normal distribution corresponding to the null distribution (the mean\n",
    "# is the value of the null hypothesis, and the standard deviation is equal to the \n",
    "# standard error) and the rejection area\n",
    "x = np.arange(-3*se, 3*se, 6*se/1000)\n",
    "y = scipy.stats.norm(scale=se).pdf(x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x,y)\n",
    "ax.set_xlim([-3*se, 3*se])\n",
    "\n",
    "z_score = scipy.stats.norm(scale=se).ppf(1-SL)\n",
    "x = np.arange(z_score, 3*se, 6*se/1000)\n",
    "y = scipy.stats.norm(scale=se).pdf(x)\n",
    "ax.fill_between(x, 0, y, color='red', alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We overlap with an alternative distribution which mean is the desired effect size and\n",
    "# standard deviation is the standard error\n",
    "lim_x = [min(1-3*se,-3*se), max(1+3*se, 3*se)]\n",
    "\n",
    "x = np.arange(lim_x[0], lim_x[1], 6*se/1000)\n",
    "y1 = scipy.stats.norm(scale=se).pdf(x)\n",
    "y2 = scipy.stats.norm(loc=1,scale=se).pdf(x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x,y1)\n",
    "ax.plot(x,y2)\n",
    "ax.set_xlim(lim_x)\n",
    "\n",
    "# Plotting how much of th second distribution overlaps\n",
    "# with the first distribution\n",
    "z_score = scipy.stats.norm(scale=se).ppf(1-SL)\n",
    "x = np.arange(z_score, lim_x[1], 6*se/1000)\n",
    "y = scipy.stats.norm(loc=1, scale=se).pdf(x)\n",
    "ax.fill_between(x, 0, y, color='red', alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The power value corresponds to the area of the second distribution that overlaps with the rejection\n",
    "# area of the first distribution\n",
    "power = 1 - scipy.stats.norm(loc=1, scale=se).cdf(z_score)\n",
    "print(power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What sample size should we choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
